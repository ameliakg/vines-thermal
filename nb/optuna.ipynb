{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8bedc-c492-4025-8ab5-ac58dc841983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook for optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63f7ea2d-8630-4092-8a63-3d9850d95de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nben/.conda/envs/vines/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import os, warnings\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np \n",
    "import scipy as sp\n",
    "import json\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import skimage as ski\n",
    "import sklearn as skl\n",
    "\n",
    "#from plantcv import plantcv as pcv\n",
    "import flyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d804dedc-c26f-4eef-8053-70674ba05d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset loader class\n",
    "class FlirDataset(torch.utils.data.Dataset):\n",
    "    \"\"\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, k):\n",
    "        return self.samples[k]\n",
    "    def __init__(self, path, datatype='train', image_subsize=64, stride=None): \n",
    "        from glob import glob\n",
    "        from pathlib import Path\n",
    "        path = Path(path)\n",
    "        if datatype == \"train\":\n",
    "            tt = \"train\"\n",
    "        elif datatype == \"test\":\n",
    "            tt = \"test\"\n",
    "        elif datatype == \"validation\":\n",
    "            tt = \"validation\"\n",
    "        elif datatype is None:\n",
    "            tt = \"non\"\n",
    "        else:\n",
    "            raise ValueError(\"datatype must be 'train', 'test', 'validation', or None\")\n",
    "        annot_pattern = str(path / \"training\" / \"annotated\" / tt / \"*.png\")\n",
    "        annot_filenames = glob(annot_pattern)\n",
    "        annot_ims = {\n",
    "            Path(filename).name[:-4]: plt.imread(filename)\n",
    "            for filename in annot_filenames}\n",
    "        flir_pattern = str(path / \"*\" / \"thermal\" / \"*.jpg\")\n",
    "        flir_filenames = {\n",
    "            Path(file).name[:-4]: file\n",
    "            for file in glob(flir_pattern)}\n",
    "        self.names = list(annot_ims.keys())\n",
    "        flir_ims = {\n",
    "            key: self.load_flir(flir_filenames[key])\n",
    "            for key in self.names}\n",
    "        self.images = flir_ims\n",
    "        self.annots = annot_ims\n",
    "        #for (file, ims, annot) in zip(list(self.names()), list(self.images()), list(self.annots())):\n",
    "            #if ims[1].shape[:2] != annot.shape[:2]:\n",
    "               # plt.imshow(annot)\n",
    "                #print(file, ims[1].shape, annot.shape)\n",
    "        imsz = image_subsize\n",
    "        stride = imsz if stride is None else stride\n",
    "        sdata = {}\n",
    "        for key in self.names:\n",
    "            (thr_im, opt_im) = self.images[key]\n",
    "            ann_im = self.annots[key]\n",
    "            for (rno, rowidx) in enumerate(range(0, opt_im.shape[0], stride)):\n",
    "                if rowidx + imsz >= opt_im.shape[0]:\n",
    "                    continue\n",
    "                for (cno, colidx) in enumerate(range(0, opt_im.shape[1], stride)):\n",
    "                    if colidx + imsz >= opt_im.shape[1]:\n",
    "                        continue\n",
    "                    # Get the subimage from the optical and annotation images:\n",
    "                    opt_sub = opt_im[rowidx:rowidx + imsz, colidx:colidx + imsz]\n",
    "                    thr_sub = opt_im[rowidx:rowidx + imsz, colidx:colidx + imsz]\n",
    "                    ann_sub = ann_im[rowidx:rowidx + imsz, colidx:colidx + imsz]\n",
    "                    tup = (rowidx, colidx, opt_sub, ann_sub, thr_sub)\n",
    "                    sdata[key, rno, cno] = tup\n",
    "        self.sample_data = sdata\n",
    "        self.masks = {}\n",
    "        self.image_subsize = image_subsize\n",
    "        self.samples = []\n",
    "        for ((k,rno,cno), tup) in sdata.items():\n",
    "            (rowidx, colidx, opt_sub, ann_sub, thr_sub) = tup\n",
    "            #plant_pixels = np.all(ann_sub[:,:,0:3] == [1, 0, 0], axis=2)\n",
    "            plant_pixels = (ann_sub[:,:,0] - ann_sub[:,:,1] - ann_sub[:,:,2] > 0.9)\n",
    "            self.masks[k, rno, cno] = plant_pixels\n",
    "            opt_for_torch = torch.permute(\n",
    "                torch.tensor(opt_sub, dtype=torch.float) / 255,\n",
    "                (2, 0, 1))\n",
    "            ann_frac = 1 - np.sum(plant_pixels) / plant_pixels.size\n",
    "            #ann_frac = torch.tensor(\n",
    "            #    round(ann_frac * 999),\n",
    "            #    dtype=torch.long)\n",
    "            ann_frac = torch.tensor(ann_frac, dtype=torch.float)\n",
    "            #sample = (opt_for_torch, ann_frac)\n",
    "            mask = torch.tensor(self.masks[k, rno, cno], dtype=torch.float32)\n",
    "            sample = (opt_for_torch, mask[None,...])\n",
    "            self.samples.append(sample)\n",
    "    def load_flir(self, filename, thermal_unit='celsius'):\n",
    "        \"\"\"Loads and returns the portion of a FLIR image file that contains both\n",
    "        optical and thermal data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        filename : pathlike\n",
    "            A ``pathname.Path`` object or a string representing the filename of\n",
    "            image that is to be loaded.\n",
    "        thermal_unit : {'celsius' | 'kelvin' | 'fahrenheit'}, optional\n",
    "            What temperature units to return; the default is ``'celsius'``.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        optical_image : numpy.ndarray\n",
    "            An image-array with shape ``(rows, cols, 3)`` containing the RGB\n",
    "            optical of the visual FLIR image.\n",
    "        thermal_image : numpy.ndarray\n",
    "            An image-array with shape ``(rows, cols)`` containing the thermal\n",
    "            values in Celsius.\n",
    "        \"\"\"\n",
    "        from os import fspath\n",
    "        from PIL import Image\n",
    "        import flyr\n",
    "        # Make sure we have a path:\n",
    "        filename = fspath(filename)\n",
    "        # Import the raw image data:\n",
    "        flir_image = flyr.unpack(filename)\n",
    "        # Extract the optical and thermal data:\n",
    "        opt = flir_image.optical\n",
    "        #plt.imshow(opt)\n",
    "        thr = getattr(flir_image, thermal_unit)\n",
    "        pip = flir_image.pip_info\n",
    "        x0 = pip.offset_x\n",
    "        y0 = pip.offset_y\n",
    "        ratio = pip.real_to_ir\n",
    "        ratio = opt.shape[0] / thr.shape[0] / ratio\n",
    "        # Resize the thermal image to match the optical image in resolution:\n",
    "        (opt_rs, opt_cs, _) = opt.shape\n",
    "        (thr_rs, thr_cs) = np.round(np.array(thr.shape) * ratio).astype(int)\n",
    "        thr = np.array(Image.fromarray(thr).resize([thr_cs, thr_rs]))\n",
    "        #plt.imshow(thr)\n",
    "        x0 = round(opt_cs // 2 - thr_cs // 2 + x0)\n",
    "        y0 = round(opt_rs // 2 - thr_rs // 2 + y0)\n",
    "        return (thr, opt[y0:y0+thr_rs, x0:x0+thr_cs, :])\n",
    "    def pred_all(self, model):\n",
    "        \"\"\"Returns predicted segmentations for all items in the dataset.\"\"\"\n",
    "        shape = (self.image_subsize, self.image_subsize)\n",
    "        inpts = torch.stack([img for (img,_) in self.samples if img.shape[1:] == shape], axis=0).detach()\n",
    "        targs = torch.stack([trg for (_,trg) in self.samples if trg.shape[1:] == shape], axis=0).detach()\n",
    "        preds = model(inpts).detach()\n",
    "        if model.logits:\n",
    "            preds = torch.sigmoid(preds)\n",
    "        return (\n",
    "            torch.permute(inpts, (0,2,3,1)),\n",
    "            preds[:, 0, ...],\n",
    "            torch.permute(targs, (0,2,3,1)))\n",
    "    def extract_temp(self, model):\n",
    "        \"\"\"Extracts temperature from predicted plant segmentation\"\"\"\n",
    "        results = []\n",
    "        for ((input, _), sdata) in zip(self.samples, self.sample_data.items()):\n",
    "            thermal_im = sdata[-1]\n",
    "            pred = model(input[None,...]) #need none bc model expecting batch, so gives it a batch dimension\n",
    "            # prediction is > 0.5 if pred is > 0 because pred is in logits and \n",
    "            # sigmoid() converts 0 to 0.5.\n",
    "            # So the line that follows is equivalent to:\n",
    "            # pred = torch.sigmoid(pred[0]) > 0.5\n",
    "            pred = pred[0, ...] > 0\n",
    "            thermal_inseg = thermal_im[pred].flatten()\n",
    "            thermal_outseg = thermal_im[~pred].flatten()\n",
    "            results.append((thermal_inseg, thermal_outsef))\n",
    "        return results\n",
    "    def image_temps(self, model):\n",
    "        \"\"\"Gives us back images matched to temperatures\"\"\"\n",
    "        (_,preds,_) = self.pred_all(model)\n",
    "        result = {}\n",
    "        for (pred, ((file,r,c),sdata)) in zip(preds, self.sample_data.items()):\n",
    "            thermal = sdata[-1]\n",
    "            plant_temp = torch.sum(pred*thermal)\n",
    "            pred = 1-pred\n",
    "            none_temp = torch.sum(pred*thermal)\n",
    "            if file not in results: \n",
    "                results[file] = []\n",
    "            result[file].append((r, c, plant_temp, none_temp, pred))\n",
    "        df = []\n",
    "        for file, patches in result.items():\n",
    "            plant_temp = torch.sum([t for (_,_,t,_,_) in patches])/torch.sum([w for (_,_,_,_,w) in patches])\n",
    "            none_temp = torch.sum([t for (_,_,_,t,_) in patches])/torch.sum([1-w for (_,_,_,_,w) in patches])\n",
    "            df.append({\"file\":file, \"plant_temp\":plant_temp, \"none_temp\":none_temp})\n",
    "        return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b2f0c0-b79a-4deb-b6aa-f5f1063480ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#name the datasets\n",
    "#dataset_path = \"/Users/ameliakeyser-gibson/Documents/SEFS/Kim Lab/vines grant/thermal/monthly images\"\n",
    "#dataset_path = \"/Users/nben/Documents/eScience/Accelerator/Vines-Thermal/monthly images\"\n",
    "dataset_path = \"/data/vines-thermal/images\"\n",
    "image_subsize = 128\n",
    "stride = 32\n",
    "\n",
    "train_ds = FlirDataset(dataset_path, datatype=\"train\", image_subsize=image_subsize, stride=stride)\n",
    "test_ds = FlirDataset(dataset_path, datatype=\"test\", image_subsize=image_subsize)\n",
    "train_eval_ds = FlirDataset(dataset_path, datatype=\"train\", image_subsize=image_subsize)\n",
    "#none_ds = FlirDataset(dataset_path, datatype=None, image_subsize=image_subsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13e24c1f-caf5-476f-83b6-3ba6f6e731bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================================\n",
    "#U-net code\n",
    "# Dependencies\n",
    "def convrelu(in_channels, out_channels,\n",
    "             kernel=3, padding=None, stride=1, bias=True, inplace=True):\n",
    "    \"\"\"Shortcut for creating a PyTorch 2D convolution followed by a ReLU.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        The number of input channels in the convolution.\n",
    "    out_channels : int\n",
    "        The number of output channels in the convolution.\n",
    "    kernel : int, optional\n",
    "        The kernel size for the convolution (default: 3).\n",
    "    padding : int or None, optional\n",
    "        The padding size for the convolution; if `None` (the default), then\n",
    "        chooses a padding size that attempts to maintain the image-size.\n",
    "    stride : int, optional\n",
    "        The stride to use in the convolution (default: 1).\n",
    "    bias : boolean, optional\n",
    "        Whether the convolution has a learnable bias (default: True).\n",
    "    inplace : boolean, optional\n",
    "        Whether to perform the ReLU operation in-place (default: True).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.nn.Sequential\n",
    "        The model of a 2D-convolution followed by a ReLU operation.\n",
    "    \"\"\"\n",
    "    if padding is None:\n",
    "        padding = kernel_default_padding(kernel)\n",
    "    return torch.nn.Sequential(\n",
    "        torch.nn.Conv2d(in_channels, out_channels, kernel,\n",
    "                        padding=padding, bias=bias),\n",
    "        torch.nn.ReLU(inplace=inplace))\n",
    "\n",
    "#===============================================================================\n",
    "# Image-based CNN Model Code\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "    \"\"\"a U-Net with a ResNet18 backbone for learning visual area labels.\n",
    "\n",
    "    The `UNet` class implements a [\"U-Net\"](https://arxiv.org/abs/1505.04597)\n",
    "    with a [ResNet-18](https://pytorch.org/hub/pytorch_vision_resnet/) bacbone.\n",
    "    The class inherits from `torch.nn.Module`.\n",
    "    \n",
    "    The original implementation of this class was by Shaoling Chen\n",
    "    (sc6995@nyu.edu), and additional modifications have been made by Noah C.\n",
    "    Benson (nben@uw.edu).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feature_count : int\n",
    "        The number of channels (features) in the input image. When using an\n",
    "        `HCPVisualDataset` object for training, this value should be set to 4\n",
    "        if the dataset uses the `'anat'` or `'func'` features and 8 if it uses\n",
    "        the `'both'` features.\n",
    "    segment_count : int\n",
    "        The number of segments (AKA classes, labels) in the output data. For\n",
    "        V1-V3 this is typically either 3 (V1, V2, V3) or 6 (LV1, LV2, LV3, RV1,\n",
    "        RV2, RV3).\n",
    "    base_model : model name or tuple, optional\n",
    "        The name of the model that is to be used as the base/backbone of the\n",
    "        UNet. The default is `'resnet18'`, but \n",
    "    pretrained : boolean, optional\n",
    "        Whether to use a pretrained base model for the backbone (`True`) or not\n",
    "        (`False`). The default is `False`.\n",
    "    logits : boolean, optional\n",
    "        Whether the model should return logits (`True`) or probabilities\n",
    "        (`False`). The default is `True`.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    pretrained_base : boolean\n",
    "        `True` if the base model used in this `UNet` was originally pre-trained\n",
    "        and `False` otherwise.\n",
    "    base_model : PyTorch Module\n",
    "        The ResNet-18 model that is used as the backbone of the `UNet` model.\n",
    "    base_layers : list of PyTorch Modules\n",
    "        The ResNet-18 layers that are used in the backbone of the `UNet` model.\n",
    "    feature_count : int\n",
    "        The number of input channels (features) that the model expects in input\n",
    "        images.\n",
    "    segment_count : int\n",
    "        The number of segments (labels) predicted by the model.\n",
    "    logits : bool\n",
    "        `True` if the output of the model is in logits and `False` if its output\n",
    "        is in probabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, feature_count=3, segment_count=1,\n",
    "                 base_model='resnet18',\n",
    "                 pretrained=True,\n",
    "                 logits=True):\n",
    "        import torch.nn as nn\n",
    "        # Initialize the super-class.\n",
    "        super().__init__()\n",
    "        # Store some basic attributes.\n",
    "        self.feature_count = feature_count\n",
    "        self.segment_count = segment_count\n",
    "        self.pretrained = pretrained\n",
    "        self.logits = logits\n",
    "        # Set up the base model and base layers for the model.\n",
    "        if pretrained:\n",
    "            weights = 'IMAGENET1K_V1'\n",
    "        else:\n",
    "            weights = None\n",
    "        import torchvision.models as mdls\n",
    "        base_model = getattr(mdls, base_model)\n",
    "        try:\n",
    "            base_model = base_model(weights=weights)\n",
    "        except TypeError:\n",
    "            base_model = base_model(pretrained=pretrained)\n",
    "        # Not sure we should store the base model; seems like a good idea, but\n",
    "        # does it get caught up in PyTorch's Module data when we do?\n",
    "        #self.base_model = resnet18(pretrained=pretrained)\n",
    "        # Because the input size may not be 3 and the output size may not be 3,\n",
    "        # we want to add an additional \n",
    "        if feature_count != 3:\n",
    "            # Adjust the first convolution's number of input channels.\n",
    "            c1 = base_model.conv1\n",
    "            base_model.conv1 = nn.Conv2d(\n",
    "                feature_count, c1.out_channels,\n",
    "                kernel_size=c1.kernel_size, stride=c1.stride,\n",
    "                padding=c1.padding, bias=c1.bias)\n",
    "        base_layers = list(base_model.children())\n",
    "        #self.base_layers = base_layers\n",
    "        # Make the U-Net layers out of the base-layers.\n",
    "        # size = (N, 64, H/2, W/2)\n",
    "        self.layer0 = nn.Sequential(*base_layers[:3]) \n",
    "        self.layer0_1x1 = convrelu(64, 64, 1, 0)\n",
    "        # size = (N, 64, H/4, W/4)\n",
    "        self.layer1 = nn.Sequential(*base_layers[3:5])\n",
    "        self.layer1_1x1 = convrelu(64, 64, 1, 0)\n",
    "        # size = (N, 128, H/8, W/8)        \n",
    "        self.layer2 = base_layers[5]\n",
    "        self.layer2_1x1 = convrelu(128, 128, 1, 0)  \n",
    "        # size = (N, 256, H/16, W/16)\n",
    "        self.layer3 = base_layers[6]  \n",
    "        self.layer3_1x1 = convrelu(256, 256, 1, 0)  \n",
    "        # size = (N, 512, H/32, W/32)\n",
    "        self.layer4 = base_layers[7]\n",
    "        self.layer4_1x1 = convrelu(512, 512, 1, 0)\n",
    "        # The up-swing of the UNet; we will need to upsample the image.\n",
    "        self.upsample = nn.Upsample(scale_factor=2,\n",
    "                                    mode='bilinear',\n",
    "                                    align_corners=True)\n",
    "        self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n",
    "        self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n",
    "        self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n",
    "        self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n",
    "        self.conv_original_size0 = convrelu(feature_count, 64, 3, 1)\n",
    "        self.conv_original_size1 = convrelu(64, 64, 3, 1)\n",
    "        self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n",
    "        self.conv_last = nn.Conv2d(64, segment_count, 1)\n",
    "    def forward(self, input):\n",
    "        # Do the original size convolutions.\n",
    "        x_original = self.conv_original_size0(input)\n",
    "        x_original = self.conv_original_size1(x_original)\n",
    "        # Now the front few layers, which we save for adding back in on the UNet\n",
    "        # up-swing below.\n",
    "        layer0 = self.layer0(input)\n",
    "        layer1 = self.layer1(layer0)\n",
    "        layer2 = self.layer2(layer1)\n",
    "        layer3 = self.layer3(layer2)        \n",
    "        layer4 = self.layer4(layer3)\n",
    "        # Now, we start the up-swing; each step must upsample the image.\n",
    "        layer4 = self.layer4_1x1(layer4)\n",
    "        # Up-swing Step 1\n",
    "        x = self.upsample(layer4)\n",
    "        layer3 = self.layer3_1x1(layer3)\n",
    "        x = torch.cat([x, layer3], dim=1)\n",
    "        x = self.conv_up3(x)\n",
    "        # Up-swing Step 2\n",
    "        x = self.upsample(x)\n",
    "        layer2 = self.layer2_1x1(layer2)\n",
    "        x = torch.cat([x, layer2], dim=1)\n",
    "        x = self.conv_up2(x)\n",
    "        # Up-swing Step 3\n",
    "        x = self.upsample(x)\n",
    "        layer1 = self.layer1_1x1(layer1)\n",
    "        x = torch.cat([x, layer1], dim=1)\n",
    "        x = self.conv_up1(x)\n",
    "        # Up-swing Step 4\n",
    "        x = self.upsample(x)\n",
    "        layer0 = self.layer0_1x1(layer0)\n",
    "        x = torch.cat([x, layer0], dim=1)\n",
    "        x = self.conv_up0(x)\n",
    "        # Up-swing Step 5\n",
    "        x = self.upsample(x)\n",
    "        x = torch.cat([x, x_original], dim=1)\n",
    "        x = self.conv_original_size2(x)        \n",
    "        # And the final convolution.\n",
    "        out = self.conv_last(x)\n",
    "        if not self.logits:\n",
    "            out = torch.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "501743ce-d474-4e0d-8805-c9fa4f4cb719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used in dice coefficient function\n",
    "def is_logits(data): \n",
    "    \"\"\"Attempts to guess whether the given PyTorch tensor contains logits.\n",
    "\n",
    "    If the argument `data` contains only values that are no less than 0 and no\n",
    "    greater than 1, then `False` is returned; otherwise, `True` is returned.\n",
    "    \"\"\"\n",
    "    if   (data > 1).any(): return True\n",
    "    elif (data < 0).any(): return True\n",
    "    else:                  return False\n",
    "# writing a test DICE loss coefficient        \n",
    "def dice_loss(pred, gold, logits=None, smoothing=0, metrics=None):\n",
    "    \"\"\"Returns the loss based on the dice coefficient.\n",
    "    \n",
    "    `dice_loss(pred, gold)` returns the dice-coefficient loss between the\n",
    "    tensors `pred` and `gold` which must be the same shape and which should\n",
    "    represent probabilities. The first two dimensions of both `pred` and `gold`\n",
    "    must represent the batch-size and the classes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pred : tensor\n",
    "        The predicted probabilities of each class.\n",
    "    gold : tensor\n",
    "        The gold-standard labels for each class.\n",
    "    logits : boolean, optional\n",
    "        Whether the values in `pred` are logits--i.e., unnormalized scores that\n",
    "        have not been run through a sigmoid calculation already. If this is\n",
    "        `True`, then the BCE starts by calculating the sigmoid of the `pred`\n",
    "        argument. If `None`, then attempts to deduce whether the input is or is\n",
    "        not logits. The default is `None`.\n",
    "    smoothing : number, optional\n",
    "        The smoothing coefficient `s`. The default is `1`.\n",
    "    metrics : dict or None, optional\n",
    "        An optional dictionary into which the key `'dice'` should be inserted\n",
    "        with the dice-loss as the value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The dice-coefficient loss of the prediction.\n",
    "    \"\"\"\n",
    "    pred = pred.contiguous()\n",
    "    gold = gold.contiguous()\n",
    "    if logits is None: logits = is_logits(pred) #sometimes logit, sometimes probability, this func automatically detect whether logit or prob\n",
    "    if logits: pred = torch.sigmoid(pred)\n",
    "    intersection = (pred * gold) #high probabilities get higher values, low get low, gold is 0s and 1s, this gives predicted probabilities where true value is correct\n",
    "    pred = pred**2 #noah checking if we should be squaring here\n",
    "    gold = gold**2\n",
    "    while len(intersection.shape) > 2:\n",
    "        intersection = intersection.sum(dim=-1)\n",
    "        pred = pred.sum(dim=-1)\n",
    "        gold = gold.sum(dim=-1)\n",
    "    if smoothing is None: smoothing = 0\n",
    "    loss = (1 - ((2 * intersection + smoothing) / (pred + gold + smoothing)))\n",
    "    # Average the loss across classes then take the mean across batch elements.\n",
    "    loss = loss.mean(dim=1).mean() #utilities that we can ignore - mean across channels and then across all the batches\n",
    "    if metrics is not None:\n",
    "        if 'dice' not in metrics: metrics['dice'] = 0.0\n",
    "        metrics['dice'] += loss.data.cpu().numpy() * gold.size(0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "542b1cc1-ec14-40ee-b223-bc7e5cb6ddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(lr, gamma, batch_size, n_epochs=10, base_model='resnet18', print=print):\n",
    "    if print is None: \n",
    "        print = lambda *args,**kw: None\n",
    "    print(\"Training Model...\")\n",
    "    print(f\"  lr    = {lr}\")\n",
    "    print(f\"  gamma = {gamma}\")\n",
    "    print(f\"  bsize = {batch_size}\")\n",
    "    \n",
    "    model = UNet(base_model=base_model)\n",
    "    \n",
    "    # Make the optimizer and LR-manager:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) #optimizer handles updating the parameters each step\n",
    "    steplr = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=1,\n",
    "        gamma=gamma) #take smaller steps in the learning rate as you get closer\n",
    "    \n",
    "    # Declare our loss function: what's actually getting minimized\n",
    "    bce_loss_fn = torch.nn.BCEWithLogitsLoss()  #loss function that works for pixels and logits- well established\n",
    "    dice_loss_fn = lambda a, b: dice_loss(a, b, smoothing=0, logits=True)\n",
    "    both_loss_fn = lambda a,b,w=0.5: (1-w)*bce_loss_fn(a,b) + w*dice_loss_fn(a,b)\n",
    "    \n",
    "    \n",
    "    # Make the dataloaders:\n",
    "    train_dloader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True)\n",
    "    test_dloader = torch.utils.data.DataLoader(\n",
    "        test_ds,\n",
    "        batch_size=len(test_ds),\n",
    "        shuffle=False)\n",
    "    train_eval_dloader = torch.utils.data.DataLoader(\n",
    "        train_eval_ds,\n",
    "        batch_size=len(train_eval_ds),\n",
    "        shuffle=False)\n",
    "    \n",
    "    # Now we start the optimization loop:\n",
    "    for epoch_num in range(n_epochs):\n",
    "        print(f\"    * Epoch: {epoch_num}\")\n",
    "        #loss_fn = lambda a,b: both_loss_fn(a, b, w=(epoch_num + 1)/ n_epochs)\n",
    "        loss_fn = both_loss_fn\n",
    "        # Put the model in train mode:\n",
    "        model.train()\n",
    "        # In each epoch, we go through each training sample once; the dataloader\n",
    "        # gives these to us in batches:\n",
    "        total_train_loss = 0\n",
    "        for (inputs, targets) in train_dloader:\n",
    "            # We're starting a new step, so we reset the gradients.\n",
    "            optimizer.zero_grad()\n",
    "            # Calculate the model prediction for these inputs.\n",
    "            preds = model(inputs)\n",
    "            # Calculate the loss between the prediction and the actual outputs.\n",
    "            train_loss = loss_fn(preds, targets) #sigmoid gives the probability but don't need sigmoid bc of BCE w/logit loss\n",
    "            # Have PyTorch backward-propagate the gradients.\n",
    "            train_loss.backward()\n",
    "            # Have the optimizer take a step: (update the parameters)\n",
    "            optimizer.step()\n",
    "            # Add up the total training loss:\n",
    "            total_train_loss += float(train_loss.detach())*len(targets)\n",
    "            train_loss = None\n",
    "        # LR Scheduler step:\n",
    "        steplr.step() #make the learning rate smaller\n",
    "        mean_train_loss = total_train_loss / len(train_ds)\n",
    "        if not np.isfinite(mean_train_loss):\n",
    "            return (model, np.nan)\n",
    "        # Now that we've finished training, put the model back in evaluation mode.\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            ## Evaluate the model using the test data.\n",
    "            total_test_dice_loss = 0\n",
    "            total_test_bce_loss = 0\n",
    "            total_test_loss = 0\n",
    "            for (inputs, targets) in test_dloader:\n",
    "                preds = model(inputs)\n",
    "                test_loss = loss_fn(preds, targets)\n",
    "                total_test_loss += float(test_loss.detach()) * len(targets) # changed from train loss\n",
    "                total_test_dice_loss += float(dice_loss_fn(preds, targets).detach()) * len(targets)\n",
    "                total_test_bce_loss += float(bce_loss_fn(preds, targets).detach()) * len(targets)\n",
    "            mean_test_loss = total_test_loss / len(test_ds)\n",
    "            mean_test_dice_loss = total_test_dice_loss / len(test_ds)\n",
    "            mean_test_bce_loss = total_test_bce_loss / len(test_ds)\n",
    "            total_train_dice_loss = 0\n",
    "            total_train_bce_loss = 0\n",
    "            for (inputs, targets) in train_eval_dloader:\n",
    "                preds = model(inputs)\n",
    "                total_train_dice_loss += float(dice_loss_fn(preds, targets).detach()) * len(targets)\n",
    "                total_train_bce_loss += float(bce_loss_fn(preds, targets).detach()) * len(targets)\n",
    "            mean_train_dice_loss = total_train_dice_loss / len(train_eval_ds)\n",
    "            mean_train_bce_loss = total_train_bce_loss / len(train_eval_ds)\n",
    "        # Print something about this step:\n",
    "        print(\n",
    "            f\"      train loss: \"\n",
    "            f\"{mean_train_loss:6.3f} [{mean_train_dice_loss:6.3f} {mean_train_bce_loss:6.3f}]\")\n",
    "        print(\n",
    "            f\"      test loss: \"\n",
    "            f\"{mean_test_loss:6.3f} [{mean_test_dice_loss:6.3f} {mean_test_bce_loss:6.3f}]\")\n",
    "    # After the optimizer has run, print out what it's found:\n",
    "    print(\"Final result:\")\n",
    "    print(f\"  train dice loss = \", float(mean_train_dice_loss))\n",
    "    print(f\"  test dice loss = \", float(mean_test_dice_loss))\n",
    "    return (model, float(mean_test_dice_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c82648d-ccae-4edb-a31d-a2f3c73b58bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 13:19:20,355] A new study created in RDB with name: vines-thermal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "  lr    = 0.00010537981961197495\n",
      "  gamma = 0.889744910964914\n",
      "  bsize = 468\n",
      "    * Epoch: 0\n",
      "      train loss:  0.639 [ 0.661  0.496]\n",
      "      test loss:  0.570 [ 0.649  0.491]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.510 [ 0.665  0.334]\n",
      "      test loss:  0.512 [ 0.678  0.347]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.388 [ 0.545  0.252]\n",
      "      test loss:  0.380 [ 0.521  0.239]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.368 [ 0.512  0.235]\n",
      "      test loss:  0.352 [ 0.486  0.218]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.350 [ 0.498  0.206]\n",
      "      test loss:  0.336 [ 0.478  0.193]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.336 [ 0.482  0.191]\n",
      "      test loss:  0.324 [ 0.465  0.182]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.324 [ 0.471  0.180]\n",
      "      test loss:  0.317 [ 0.458  0.177]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.314 [ 0.451  0.175]\n",
      "      test loss:  0.303 [ 0.437  0.169]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 13:38:16,564] Trial 0 finished with value: 0.4285999536514282 and parameters: {'lr': 0.00010537981961197495, 'gamma': 0.889744910964914, 'batch_size': 468}. Best is trial 0 with value: 0.4285999536514282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.301 [ 0.441  0.168]\n",
      "      test loss:  0.296 [ 0.429  0.163]\n",
      "Final result:\n",
      "  train dice loss =  0.4410865604877472\n",
      "  test dice loss =  0.4285999536514282\n",
      "Training Model...\n",
      "  lr    = 0.00243054164644822\n",
      "  gamma = 0.7256948531415367\n",
      "  bsize = 987\n",
      "    * Epoch: 0\n",
      "      train loss:  4.850 [ 0.665 25.757]\n",
      "      test loss: 12.402 [ 0.656 24.149]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.781 [ 0.636  0.897]\n",
      "      test loss:  0.698 [ 0.619  0.778]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.638 [ 0.622  0.733]\n",
      "      test loss:  0.674 [ 0.619  0.728]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.610 [ 0.609  0.723]\n",
      "      test loss:  0.654 [ 0.603  0.705]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.583 [ 0.602  0.607]\n",
      "      test loss:  0.611 [ 0.600  0.623]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.566 [ 0.618  0.594]\n",
      "      test loss:  0.618 [ 0.615  0.622]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.554 [ 0.623  0.592]\n",
      "      test loss:  0.619 [ 0.619  0.619]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.544 [ 0.617  0.577]\n",
      "      test loss:  0.611 [ 0.615  0.607]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.535 [ 0.608  0.556]\n",
      "      test loss:  0.599 [ 0.607  0.592]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 13:59:12,776] Trial 1 finished with value: 0.5985651612281799 and parameters: {'lr': 0.00243054164644822, 'gamma': 0.7256948531415367, 'batch_size': 987}. Best is trial 0 with value: 0.4285999536514282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.527 [ 0.600  0.539]\n",
      "      test loss:  0.587 [ 0.599  0.575]\n",
      "Final result:\n",
      "  train dice loss =  0.6002194881439209\n",
      "  test dice loss =  0.5985651612281799\n",
      "Training Model...\n",
      "  lr    = 0.0023938713520738415\n",
      "  gamma = 0.29674350012202966\n",
      "  bsize = 446\n",
      "    * Epoch: 0\n",
      "      train loss:  4.554 [ 0.638  0.734]\n",
      "      test loss:  0.689 [ 0.633  0.745]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.624 [ 0.680  0.570]\n",
      "      test loss:  0.653 [ 0.675  0.632]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.493 [ 0.622  0.390]\n",
      "      test loss:  0.637 [ 0.669  0.605]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.428 [ 0.535  0.355]\n",
      "      test loss:  0.521 [ 0.560  0.482]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.411 [ 0.533  0.330]\n",
      "      test loss:  0.517 [ 0.565  0.468]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.398 [ 0.532  0.321]\n",
      "      test loss:  0.504 [ 0.563  0.446]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.396 [ 0.528  0.315]\n",
      "      test loss:  0.486 [ 0.554  0.418]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.396 [ 0.526  0.313]\n",
      "      test loss:  0.474 [ 0.547  0.400]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.395 [ 0.524  0.313]\n",
      "      test loss:  0.465 [ 0.542  0.388]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 14:19:42,541] Trial 2 finished with value: 0.5362103581428528 and parameters: {'lr': 0.0023938713520738415, 'gamma': 0.29674350012202966, 'batch_size': 446}. Best is trial 0 with value: 0.4285999536514282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.395 [ 0.523  0.315]\n",
      "      test loss:  0.457 [ 0.536  0.378]\n",
      "Final result:\n",
      "  train dice loss =  0.5234775543212891\n",
      "  test dice loss =  0.5362103581428528\n",
      "Training Model...\n",
      "  lr    = 0.0018550519181360504\n",
      "  gamma = 0.9473173440816791\n",
      "  bsize = 759\n",
      "    * Epoch: 0\n",
      "      train loss:  2.081 [ 0.653  0.705]\n",
      "      test loss:  0.674 [ 0.643  0.704]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.640 [ 0.637  0.674]\n",
      "      test loss:  0.654 [ 0.628  0.679]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.595 [ 0.651  0.663]\n",
      "      test loss:  0.652 [ 0.639  0.666]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.549 [ 0.665  0.638]\n",
      "      test loss:  0.644 [ 0.651  0.637]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.496 [ 0.699  0.570]\n",
      "      test loss:  0.624 [ 0.680  0.569]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.408 [ 0.730  0.530]\n",
      "      test loss:  0.646 [ 0.733  0.560]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.325 [ 0.616  0.440]\n",
      "      test loss:  0.528 [ 0.600  0.455]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.302 [ 0.461  0.195]\n",
      "      test loss:  0.322 [ 0.453  0.191]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.275 [ 0.436  0.227]\n",
      "      test loss:  0.288 [ 0.398  0.178]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 14:40:14,835] Trial 3 finished with value: 0.3887418210506439 and parameters: {'lr': 0.0018550519181360504, 'gamma': 0.9473173440816791, 'batch_size': 759}. Best is trial 3 with value: 0.3887418210506439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.258 [ 0.425  0.205]\n",
      "      test loss:  0.274 [ 0.389  0.159]\n",
      "Final result:\n",
      "  train dice loss =  0.42526721954345703\n",
      "  test dice loss =  0.3887418210506439\n",
      "Training Model...\n",
      "  lr    = 0.00011800765399556325\n",
      "  gamma = 0.7355423883031293\n",
      "  bsize = 756\n",
      "    * Epoch: 0\n",
      "      train loss:  0.648 [ 0.659  0.634]\n",
      "      test loss:  0.640 [ 0.647  0.632]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.587 [ 0.662  0.399]\n",
      "      test loss:  0.531 [ 0.661  0.400]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.460 [ 0.634  0.287]\n",
      "      test loss:  0.459 [ 0.636  0.282]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.421 [ 0.632  0.281]\n",
      "      test loss:  0.448 [ 0.624  0.272]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.404 [ 0.571  0.265]\n",
      "      test loss:  0.401 [ 0.552  0.251]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.395 [ 0.580  0.261]\n",
      "      test loss:  0.411 [ 0.566  0.256]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.388 [ 0.551  0.247]\n",
      "      test loss:  0.382 [ 0.530  0.233]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.383 [ 0.553  0.235]\n",
      "      test loss:  0.379 [ 0.534  0.225]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.378 [ 0.542  0.232]\n",
      "      test loss:  0.370 [ 0.521  0.218]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 14:59:22,606] Trial 4 finished with value: 0.5143098831176758 and parameters: {'lr': 0.00011800765399556325, 'gamma': 0.7355423883031293, 'batch_size': 756}. Best is trial 3 with value: 0.3887418210506439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.375 [ 0.536  0.231]\n",
      "      test loss:  0.365 [ 0.514  0.216]\n",
      "Final result:\n",
      "  train dice loss =  0.5359736084938049\n",
      "  test dice loss =  0.5143098831176758\n",
      "Training Model...\n",
      "  lr    = 0.002028007658871068\n",
      "  gamma = 0.537579317675409\n",
      "  bsize = 471\n",
      "    * Epoch: 0\n",
      "      train loss:  2.027 [ 0.644  0.725]\n",
      "      test loss:  0.689 [ 0.640  0.738]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.637 [ 0.637  0.669]\n",
      "      test loss:  0.649 [ 0.627  0.671]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.601 [ 0.616  0.621]\n",
      "      test loss:  0.618 [ 0.607  0.629]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.569 [ 0.603  0.584]\n",
      "      test loss:  0.597 [ 0.595  0.598]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.546 [ 0.594  0.556]\n",
      "      test loss:  0.580 [ 0.587  0.573]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.529 [ 0.583  0.531]\n",
      "      test loss:  0.562 [ 0.575  0.549]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.517 [ 0.574  0.513]\n",
      "      test loss:  0.547 [ 0.565  0.528]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.509 [ 0.568  0.501]\n",
      "      test loss:  0.535 [ 0.556  0.513]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.504 [ 0.564  0.494]\n",
      "      test loss:  0.528 [ 0.552  0.504]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 15:18:52,121] Trial 5 finished with value: 0.5490244030952454 and parameters: {'lr': 0.002028007658871068, 'gamma': 0.537579317675409, 'batch_size': 471}. Best is trial 3 with value: 0.3887418210506439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.501 [ 0.563  0.490]\n",
      "      test loss:  0.524 [ 0.549  0.499]\n",
      "Final result:\n",
      "  train dice loss =  0.5625578165054321\n",
      "  test dice loss =  0.5490244030952454\n",
      "Training Model...\n",
      "  lr    = 0.0006978894912186143\n",
      "  gamma = 0.5081404930294314\n",
      "  bsize = 664\n",
      "    * Epoch: 0\n",
      "      train loss:  0.701 [ 0.657  0.662]\n",
      "      test loss:  0.656 [ 0.646  0.665]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.625 [ 0.633  0.605]\n",
      "      test loss:  0.619 [ 0.625  0.613]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.563 [ 0.621  0.529]\n",
      "      test loss:  0.583 [ 0.615  0.551]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.496 [ 0.599  0.421]\n",
      "      test loss:  0.516 [ 0.590  0.441]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.452 [ 0.575  0.320]\n",
      "      test loss:  0.453 [ 0.574  0.331]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.421 [ 0.557  0.285]\n",
      "      test loss:  0.424 [ 0.559  0.290]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.404 [ 0.548  0.279]\n",
      "      test loss:  0.413 [ 0.546  0.280]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.396 [ 0.542  0.277]\n",
      "      test loss:  0.406 [ 0.535  0.277]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.392 [ 0.537  0.277]\n",
      "      test loss:  0.401 [ 0.527  0.275]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 15:37:58,091] Trial 6 finished with value: 0.5225077867507935 and parameters: {'lr': 0.0006978894912186143, 'gamma': 0.5081404930294314, 'batch_size': 664}. Best is trial 3 with value: 0.3887418210506439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.390 [ 0.534  0.278]\n",
      "      test loss:  0.399 [ 0.523  0.275]\n",
      "Final result:\n",
      "  train dice loss =  0.5343525409698486\n",
      "  test dice loss =  0.5225077867507935\n",
      "Training Model...\n",
      "  lr    = 0.0008055398738833336\n",
      "  gamma = 0.541177661760208\n",
      "  bsize = 786\n",
      "    * Epoch: 0\n",
      "      train loss:  0.665 [ 0.655  0.673]\n",
      "      test loss:  0.658 [ 0.644  0.673]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.643 [ 0.655  0.527]\n",
      "      test loss:  0.580 [ 0.640  0.520]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.579 [ 0.729  0.427]\n",
      "      test loss:  0.642 [ 0.771  0.514]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.479 [ 0.748  0.481]\n",
      "      test loss:  0.789 [ 0.821  0.758]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.444 [ 0.686  0.382]\n",
      "      test loss:  0.635 [ 0.744  0.526]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.421 [ 0.617  0.301]\n",
      "      test loss:  0.490 [ 0.647  0.333]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.408 [ 0.580  0.273]\n",
      "      test loss:  0.434 [ 0.592  0.276]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.401 [ 0.563  0.264]\n",
      "      test loss:  0.412 [ 0.567  0.257]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.398 [ 0.553  0.261]\n",
      "      test loss:  0.400 [ 0.553  0.248]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 15:57:05,422] Trial 7 finished with value: 0.5438653230667114 and parameters: {'lr': 0.0008055398738833336, 'gamma': 0.541177661760208, 'batch_size': 786}. Best is trial 3 with value: 0.3887418210506439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.396 [ 0.547  0.260]\n",
      "      test loss:  0.393 [ 0.544  0.243]\n",
      "Final result:\n",
      "  train dice loss =  0.5472028255462646\n",
      "  test dice loss =  0.5438653230667114\n",
      "Training Model...\n",
      "  lr    = 0.001995963783338153\n",
      "  gamma = 0.9423384090098524\n",
      "  bsize = 791\n",
      "    * Epoch: 0\n",
      "      train loss:  1.141 [ 0.663 66.809]\n",
      "      test loss: 24.737 [ 0.655 48.819]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.849 [ 0.657  0.684]\n",
      "      test loss:  0.664 [ 0.646  0.683]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.637 [ 0.633  0.657]\n",
      "      test loss:  0.633 [ 0.617  0.650]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.584 [ 0.601  0.550]\n",
      "      test loss:  0.577 [ 0.589  0.566]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.480 [ 0.621  0.414]\n",
      "      test loss:  0.528 [ 0.614  0.442]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.345 [ 0.648  0.451]\n",
      "      test loss:  0.636 [ 0.671  0.601]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.308 [ 0.497  0.261]\n",
      "      test loss:  0.449 [ 0.519  0.379]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.285 [ 0.435  0.191]\n",
      "      test loss:  0.321 [ 0.423  0.219]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.279 [ 0.427  0.172]\n",
      "      test loss:  0.284 [ 0.405  0.162]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 16:16:15,247] Trial 8 finished with value: 0.41549667716026306 and parameters: {'lr': 0.001995963783338153, 'gamma': 0.9423384090098524, 'batch_size': 791}. Best is trial 3 with value: 0.3887418210506439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.269 [ 0.433  0.162]\n",
      "      test loss:  0.286 [ 0.415  0.156]\n",
      "Final result:\n",
      "  train dice loss =  0.4326753318309784\n",
      "  test dice loss =  0.41549667716026306\n",
      "Training Model...\n",
      "  lr    = 0.0020349528272311066\n",
      "  gamma = 0.8289813940822881\n",
      "  bsize = 762\n",
      "    * Epoch: 0\n",
      "      train loss:  6.811 [ 0.650  0.731]\n",
      "      test loss:  0.683 [ 0.639  0.726]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.647 [ 0.639  0.695]\n",
      "      test loss:  0.666 [ 0.631  0.700]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.600 [ 0.633  0.664]\n",
      "      test loss:  0.653 [ 0.627  0.679]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.565 [ 0.622  0.615]\n",
      "      test loss:  0.611 [ 0.607  0.615]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.533 [ 0.600  0.539]\n",
      "      test loss:  0.555 [ 0.576  0.533]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.493 [ 0.585  0.452]\n",
      "      test loss:  0.504 [ 0.556  0.453]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.440 [ 0.546  0.341]\n",
      "      test loss:  0.434 [ 0.513  0.355]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.377 [ 0.502  0.253]\n",
      "      test loss:  0.369 [ 0.470  0.267]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.324 [ 0.456  0.193]\n",
      "      test loss:  0.321 [ 0.434  0.208]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 16:37:34,757] Trial 9 finished with value: 0.4337393045425415 and parameters: {'lr': 0.0020349528272311066, 'gamma': 0.8289813940822881, 'batch_size': 762}. Best is trial 3 with value: 0.3887418210506439.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.291 [ 0.452  0.179]\n",
      "      test loss:  0.306 [ 0.434  0.178]\n",
      "Final result:\n",
      "  train dice loss =  0.4519466459751129\n",
      "  test dice loss =  0.4337393045425415\n",
      "Training Model...\n",
      "  lr    = 0.0014346085962015944\n",
      "  gamma = 0.9853790940020313\n",
      "  bsize = 138\n",
      "    * Epoch: 0\n",
      "      train loss:  0.656 [ 0.829  0.773]\n",
      "      test loss:  0.913 [ 0.863  0.963]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.284 [ 0.450  0.172]\n",
      "      test loss:  0.305 [ 0.441  0.169]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.260 [ 0.384  0.130]\n",
      "      test loss:  0.248 [ 0.374  0.122]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.235 [ 0.370  0.124]\n",
      "      test loss:  0.240 [ 0.363  0.118]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.222 [ 0.368  0.118]\n",
      "      test loss:  0.268 [ 0.395  0.141]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.214 [ 0.349  0.103]\n",
      "      test loss:  0.239 [ 0.362  0.116]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.207 [ 0.341  0.099]\n",
      "      test loss:  0.234 [ 0.360  0.108]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.202 [ 0.347  0.092]\n",
      "      test loss:  0.250 [ 0.381  0.120]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.200 [ 0.337  0.087]\n",
      "      test loss:  0.245 [ 0.370  0.119]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 16:56:46,564] Trial 10 finished with value: 0.3532413840293884 and parameters: {'lr': 0.0014346085962015944, 'gamma': 0.9853790940020313, 'batch_size': 138}. Best is trial 10 with value: 0.3532413840293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.193 [ 0.334  0.087]\n",
      "      test loss:  0.232 [ 0.353  0.111]\n",
      "Final result:\n",
      "  train dice loss =  0.3335125744342804\n",
      "  test dice loss =  0.3532413840293884\n",
      "Training Model...\n",
      "  lr    = 0.0014362882448201717\n",
      "  gamma = 0.9748305874423029\n",
      "  bsize = 30\n",
      "    * Epoch: 0\n",
      "      train loss:  0.381 [ 0.395  0.155]\n",
      "      test loss:  0.253 [ 0.371  0.135]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.238 [ 0.358  0.114]\n",
      "      test loss:  0.232 [ 0.357  0.107]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.223 [ 0.351  0.102]\n",
      "      test loss:  0.223 [ 0.350  0.096]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.210 [ 0.357  0.119]\n",
      "      test loss:  0.249 [ 0.361  0.136]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.204 [ 0.337  0.088]\n",
      "      test loss:  0.229 [ 0.355  0.103]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.192 [ 0.329  0.084]\n",
      "      test loss:  0.226 [ 0.350  0.103]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.186 [ 0.332  0.086]\n",
      "      test loss:  0.239 [ 0.357  0.121]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.182 [ 0.326  0.082]\n",
      "      test loss:  0.241 [ 0.364  0.118]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.181 [ 0.320  0.079]\n",
      "      test loss:  0.235 [ 0.352  0.117]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 17:16:09,915] Trial 11 finished with value: 0.35528892278671265 and parameters: {'lr': 0.0014362882448201717, 'gamma': 0.9748305874423029, 'batch_size': 30}. Best is trial 10 with value: 0.3532413840293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.175 [ 0.315  0.071]\n",
      "      test loss:  0.237 [ 0.355  0.119]\n",
      "Final result:\n",
      "  train dice loss =  0.31548020243644714\n",
      "  test dice loss =  0.35528892278671265\n",
      "Training Model...\n",
      "  lr    = 0.0014256623065457886\n",
      "  gamma = 0.9964299042563164\n",
      "  bsize = 22\n",
      "    * Epoch: 0\n",
      "      train loss:  0.323 [ 0.374  0.126]\n",
      "      test loss:  0.235 [ 0.358  0.112]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.222 [ 0.359  0.109]\n",
      "      test loss:  0.237 [ 0.368  0.106]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.220 [ 0.354  0.110]\n",
      "      test loss:  0.235 [ 0.365  0.106]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.219 [ 0.360  0.116]\n",
      "      test loss:  0.235 [ 0.356  0.115]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.202 [ 0.337  0.099]\n",
      "      test loss:  0.232 [ 0.355  0.109]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.196 [ 0.331  0.085]\n",
      "      test loss:  0.237 [ 0.361  0.113]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.189 [ 0.326  0.081]\n",
      "      test loss:  0.231 [ 0.361  0.102]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.203 [ 0.336  0.090]\n",
      "      test loss:  0.223 [ 0.347  0.100]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.189 [ 0.324  0.080]\n",
      "      test loss:  0.223 [ 0.343  0.102]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 17:35:36,183] Trial 12 finished with value: 0.3709631860256195 and parameters: {'lr': 0.0014256623065457886, 'gamma': 0.9964299042563164, 'batch_size': 22}. Best is trial 10 with value: 0.3532413840293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.181 [ 0.327  0.078]\n",
      "      test loss:  0.243 [ 0.371  0.114]\n",
      "Final result:\n",
      "  train dice loss =  0.32694873213768005\n",
      "  test dice loss =  0.3709631860256195\n",
      "Training Model...\n",
      "  lr    = 0.0013572102299750897\n",
      "  gamma = 0.7791685438643041\n",
      "  bsize = 12\n",
      "    * Epoch: 0\n",
      "      train loss:  0.326 [ 0.378  0.127]\n",
      "      test loss:  0.243 [ 0.369  0.117]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.228 [ 0.632  1.019]\n",
      "      test loss:  0.624 [ 0.651  0.596]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.223 [ 0.346  0.120]\n",
      "      test loss:  0.234 [ 0.361  0.106]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.200 [ 0.335  0.097]\n",
      "      test loss:  0.235 [ 0.363  0.107]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.193 [ 0.326  0.083]\n",
      "      test loss:  0.240 [ 0.365  0.115]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.186 [ 0.323  0.076]\n",
      "      test loss:  0.241 [ 0.366  0.116]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.184 [ 0.326  0.084]\n",
      "      test loss:  0.236 [ 0.357  0.114]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.181 [ 0.318  0.071]\n",
      "      test loss:  0.244 [ 0.374  0.114]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.178 [ 0.316  0.070]\n",
      "      test loss:  0.240 [ 0.369  0.111]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 17:54:09,470] Trial 13 finished with value: 0.36316773295402527 and parameters: {'lr': 0.0013572102299750897, 'gamma': 0.7791685438643041, 'batch_size': 12}. Best is trial 10 with value: 0.3532413840293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.175 [ 0.315  0.069]\n",
      "      test loss:  0.239 [ 0.363  0.114]\n",
      "Final result:\n",
      "  train dice loss =  0.3149982988834381\n",
      "  test dice loss =  0.36316773295402527\n",
      "Training Model...\n",
      "  lr    = 0.0010832523662411572\n",
      "  gamma = 0.661212671601813\n",
      "  bsize = 213\n",
      "    * Epoch: 0\n",
      "      train loss:  0.670 [ 0.643  0.620]\n",
      "      test loss:  0.627 [ 0.629  0.624]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.423 [ 0.459  0.204]\n",
      "      test loss:  0.350 [ 0.459  0.242]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.294 [ 0.420  0.151]\n",
      "      test loss:  0.276 [ 0.410  0.141]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.259 [ 0.394  0.137]\n",
      "      test loss:  0.253 [ 0.379  0.126]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.245 [ 0.388  0.126]\n",
      "      test loss:  0.255 [ 0.383  0.126]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.237 [ 0.378  0.119]\n",
      "      test loss:  0.253 [ 0.387  0.119]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.232 [ 0.373  0.115]\n",
      "      test loss:  0.247 [ 0.375  0.119]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.229 [ 0.368  0.114]\n",
      "      test loss:  0.243 [ 0.372  0.113]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.227 [ 0.367  0.112]\n",
      "      test loss:  0.244 [ 0.374  0.115]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 18:13:15,071] Trial 14 finished with value: 0.374881774187088 and parameters: {'lr': 0.0010832523662411572, 'gamma': 0.661212671601813, 'batch_size': 213}. Best is trial 10 with value: 0.3532413840293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.225 [ 0.366  0.111]\n",
      "      test loss:  0.245 [ 0.375  0.115]\n",
      "Final result:\n",
      "  train dice loss =  0.36628395318984985\n",
      "  test dice loss =  0.374881774187088\n",
      "Training Model...\n",
      "  lr    = 0.0015265848366235772\n",
      "  gamma = 0.8599055261614554\n",
      "  bsize = 216\n",
      "    * Epoch: 0\n",
      "      train loss:  0.753 [ 0.666  0.641]\n",
      "      test loss:  0.646 [ 0.651  0.640]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.406 [ 0.517  0.239]\n",
      "      test loss:  0.405 [ 0.527  0.284]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.273 [ 0.406  0.156]\n",
      "      test loss:  0.260 [ 0.388  0.132]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.245 [ 0.386  0.130]\n",
      "      test loss:  0.244 [ 0.371  0.117]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.233 [ 0.370  0.117]\n",
      "      test loss:  0.240 [ 0.366  0.114]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.223 [ 0.363  0.111]\n",
      "      test loss:  0.240 [ 0.368  0.112]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.219 [ 0.363  0.105]\n",
      "      test loss:  0.246 [ 0.378  0.115]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.218 [ 0.359  0.102]\n",
      "      test loss:  0.243 [ 0.376  0.110]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.211 [ 0.349  0.098]\n",
      "      test loss:  0.236 [ 0.364  0.108]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 18:32:09,848] Trial 15 finished with value: 0.3630700707435608 and parameters: {'lr': 0.0015265848366235772, 'gamma': 0.8599055261614554, 'batch_size': 216}. Best is trial 10 with value: 0.3532413840293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.209 [ 0.348  0.095]\n",
      "      test loss:  0.235 [ 0.363  0.106]\n",
      "Final result:\n",
      "  train dice loss =  0.34765034914016724\n",
      "  test dice loss =  0.3630700707435608\n",
      "Training Model...\n",
      "  lr    = 0.0009954925369440233\n",
      "  gamma = 0.31988108849533853\n",
      "  bsize = 234\n",
      "    * Epoch: 0\n",
      "      train loss:  0.634 [ 0.677  0.553]\n",
      "      test loss:  0.608 [ 0.658  0.558]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.395 [ 0.646  0.382]\n",
      "      test loss:  0.518 [ 0.639  0.398]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.293 [ 0.453  0.166]\n",
      "      test loss:  0.296 [ 0.443  0.149]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.275 [ 0.423  0.151]\n",
      "      test loss:  0.275 [ 0.415  0.135]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.269 [ 0.419  0.148]\n",
      "      test loss:  0.272 [ 0.412  0.133]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.268 [ 0.417  0.148]\n",
      "      test loss:  0.271 [ 0.409  0.132]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.267 [ 0.416  0.148]\n",
      "      test loss:  0.270 [ 0.408  0.132]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.268 [ 0.416  0.148]\n",
      "      test loss:  0.270 [ 0.408  0.132]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.268 [ 0.416  0.148]\n",
      "      test loss:  0.270 [ 0.408  0.132]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 18:51:04,961] Trial 16 finished with value: 0.4083790183067322 and parameters: {'lr': 0.0009954925369440233, 'gamma': 0.31988108849533853, 'batch_size': 234}. Best is trial 10 with value: 0.3532413840293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.267 [ 0.416  0.148]\n",
      "      test loss:  0.270 [ 0.408  0.132]\n",
      "Final result:\n",
      "  train dice loss =  0.41607949137687683\n",
      "  test dice loss =  0.4083790183067322\n",
      "Training Model...\n",
      "  lr    = 0.0016732982708837145\n",
      "  gamma = 0.3883275122883647\n",
      "  bsize = 115\n",
      "    * Epoch: 0\n",
      "      train loss:  0.652 [ 0.563  0.359]\n",
      "      test loss:  0.528 [ 0.576  0.480]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.286 [ 0.410  0.143]\n",
      "      test loss:  0.268 [ 0.399  0.137]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.255 [ 0.398  0.133]\n",
      "      test loss:  0.255 [ 0.381  0.128]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.244 [ 0.388  0.129]\n",
      "      test loss:  0.248 [ 0.373  0.123]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.240 [ 0.387  0.126]\n",
      "      test loss:  0.249 [ 0.374  0.125]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.238 [ 0.386  0.126]\n",
      "      test loss:  0.248 [ 0.372  0.124]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.238 [ 0.386  0.125]\n",
      "      test loss:  0.249 [ 0.373  0.124]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.237 [ 0.386  0.125]\n",
      "      test loss:  0.248 [ 0.373  0.124]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.237 [ 0.386  0.126]\n",
      "      test loss:  0.248 [ 0.373  0.124]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 19:10:01,794] Trial 17 finished with value: 0.3730434775352478 and parameters: {'lr': 0.0016732982708837145, 'gamma': 0.3883275122883647, 'batch_size': 115}. Best is trial 10 with value: 0.3532413840293884.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.237 [ 0.386  0.125]\n",
      "      test loss:  0.248 [ 0.373  0.124]\n",
      "Final result:\n",
      "  train dice loss =  0.3859237730503082\n",
      "  test dice loss =  0.3730434775352478\n",
      "Training Model...\n",
      "  lr    = 0.0006539342669215695\n",
      "  gamma = 0.9996199287678211\n",
      "  bsize = 337\n",
      "    * Epoch: 0\n",
      "      train loss:  0.647 [ 0.622  0.462]\n",
      "      test loss:  0.557 [ 0.623  0.492]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.360 [ 0.728  0.842]\n",
      "      test loss:  1.006 [ 0.742  1.270]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.275 [ 0.518  0.251]\n",
      "      test loss:  0.371 [ 0.502  0.240]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.251 [ 0.415  0.144]\n",
      "      test loss:  0.284 [ 0.425  0.144]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.232 [ 0.372  0.126]\n",
      "      test loss:  0.243 [ 0.371  0.115]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.228 [ 0.365  0.106]\n",
      "      test loss:  0.239 [ 0.363  0.115]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.220 [ 0.357  0.107]\n",
      "      test loss:  0.230 [ 0.349  0.112]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.217 [ 0.358  0.102]\n",
      "      test loss:  0.234 [ 0.358  0.110]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.213 [ 0.348  0.099]\n",
      "      test loss:  0.231 [ 0.353  0.110]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 19:29:00,012] Trial 18 finished with value: 0.3481561243534088 and parameters: {'lr': 0.0006539342669215695, 'gamma': 0.9996199287678211, 'batch_size': 337}. Best is trial 18 with value: 0.3481561243534088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.210 [ 0.345  0.093]\n",
      "      test loss:  0.227 [ 0.348  0.107]\n",
      "Final result:\n",
      "  train dice loss =  0.344547837972641\n",
      "  test dice loss =  0.3481561243534088\n",
      "Training Model...\n",
      "  lr    = 0.0005317912122778248\n",
      "  gamma = 0.6292784700743378\n",
      "  bsize = 330\n",
      "    * Epoch: 0\n",
      "      train loss:  0.562 [ 0.766  1.439]\n",
      "      test loss:  2.166 [ 0.889  3.443]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.402 [ 0.657  0.344]\n",
      "      test loss:  0.564 [ 0.693  0.434]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.303 [ 0.502  0.231]\n",
      "      test loss:  0.377 [ 0.503  0.250]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.272 [ 0.411  0.148]\n",
      "      test loss:  0.278 [ 0.412  0.144]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.257 [ 0.396  0.134]\n",
      "      test loss:  0.270 [ 0.406  0.134]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.251 [ 0.401  0.132]\n",
      "      test loss:  0.277 [ 0.414  0.140]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.248 [ 0.388  0.132]\n",
      "      test loss:  0.257 [ 0.388  0.125]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.243 [ 0.388  0.125]\n",
      "      test loss:  0.263 [ 0.396  0.129]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.242 [ 0.384  0.126]\n",
      "      test loss:  0.257 [ 0.388  0.126]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 19:49:08,851] Trial 19 finished with value: 0.39024075865745544 and parameters: {'lr': 0.0005317912122778248, 'gamma': 0.6292784700743378, 'batch_size': 330}. Best is trial 18 with value: 0.3481561243534088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.240 [ 0.384  0.124]\n",
      "      test loss:  0.258 [ 0.390  0.127]\n",
      "Final result:\n",
      "  train dice loss =  0.384029358625412\n",
      "  test dice loss =  0.39024075865745544\n",
      "Training Model...\n",
      "  lr    = 0.00033727662079477075\n",
      "  gamma = 0.8687593401247524\n",
      "  bsize = 343\n",
      "    * Epoch: 0\n",
      "      train loss:  0.555 [ 0.705  0.469]\n",
      "      test loss:  0.684 [ 0.743  0.624]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.456 [ 0.557  0.286]\n",
      "      test loss:  0.417 [ 0.554  0.280]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.375 [ 0.492  0.212]\n",
      "      test loss:  0.339 [ 0.480  0.198]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.322 [ 0.472  0.193]\n",
      "      test loss:  0.335 [ 0.477  0.194]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.282 [ 0.410  0.148]\n",
      "      test loss:  0.273 [ 0.403  0.143]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.264 [ 0.393  0.136]\n",
      "      test loss:  0.261 [ 0.385  0.136]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.254 [ 0.387  0.135]\n",
      "      test loss:  0.255 [ 0.382  0.128]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.247 [ 0.378  0.124]\n",
      "      test loss:  0.251 [ 0.377  0.125]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.238 [ 0.373  0.117]\n",
      "      test loss:  0.248 [ 0.374  0.121]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 20:08:11,348] Trial 20 finished with value: 0.37487149238586426 and parameters: {'lr': 0.00033727662079477075, 'gamma': 0.8687593401247524, 'batch_size': 343}. Best is trial 18 with value: 0.3481561243534088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.234 [ 0.374  0.120]\n",
      "      test loss:  0.248 [ 0.375  0.122]\n",
      "Final result:\n",
      "  train dice loss =  0.373599112033844\n",
      "  test dice loss =  0.37487149238586426\n",
      "Training Model...\n",
      "  lr    = 0.0011697039623479667\n",
      "  gamma = 0.9239492626126592\n",
      "  bsize = 103\n",
      "    * Epoch: 0\n",
      "      train loss:  0.467 [ 0.484  0.247]\n",
      "      test loss:  0.526 [ 0.500  0.553]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.245 [ 0.372  0.111]\n",
      "      test loss:  0.250 [ 0.378  0.123]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.223 [ 0.353  0.104]\n",
      "      test loss:  0.230 [ 0.349  0.111]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.215 [ 0.357  0.106]\n",
      "      test loss:  0.254 [ 0.381  0.127]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.209 [ 0.341  0.096]\n",
      "      test loss:  0.238 [ 0.356  0.120]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.199 [ 0.335  0.087]\n",
      "      test loss:  0.232 [ 0.354  0.111]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.194 [ 0.339  0.087]\n",
      "      test loss:  0.250 [ 0.374  0.125]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.191 [ 0.330  0.081]\n",
      "      test loss:  0.247 [ 0.358  0.135]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.188 [ 0.327  0.079]\n",
      "      test loss:  0.233 [ 0.347  0.120]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 20:33:32,536] Trial 21 finished with value: 0.3907226324081421 and parameters: {'lr': 0.0011697039623479667, 'gamma': 0.9239492626126592, 'batch_size': 103}. Best is trial 18 with value: 0.3481561243534088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.198 [ 0.366  0.143]\n",
      "      test loss:  0.265 [ 0.391  0.140]\n",
      "Final result:\n",
      "  train dice loss =  0.36560264229774475\n",
      "  test dice loss =  0.3907226324081421\n",
      "Training Model...\n",
      "  lr    = 0.0016581932240484645\n",
      "  gamma = 0.9911874637821845\n",
      "  bsize = 133\n",
      "    * Epoch: 0\n",
      "      train loss:  0.628 [ 0.720  0.593]\n",
      "      test loss:  0.748 [ 0.725  0.772]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.276 [ 0.403  0.142]\n",
      "      test loss:  0.262 [ 0.388  0.136]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.244 [ 0.379  0.135]\n",
      "      test loss:  0.257 [ 0.373  0.141]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.242 [ 0.386  0.163]\n",
      "      test loss:  0.254 [ 0.371  0.137]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.227 [ 0.357  0.109]\n",
      "      test loss:  0.234 [ 0.356  0.112]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.212 [ 0.346  0.098]\n",
      "      test loss:  0.228 [ 0.350  0.106]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.207 [ 0.345  0.098]\n",
      "      test loss:  0.237 [ 0.361  0.112]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.200 [ 0.337  0.088]\n",
      "      test loss:  0.235 [ 0.362  0.108]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.194 [ 0.333  0.086]\n",
      "      test loss:  0.231 [ 0.348  0.115]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 20:52:28,675] Trial 22 finished with value: 0.37973618507385254 and parameters: {'lr': 0.0016581932240484645, 'gamma': 0.9911874637821845, 'batch_size': 133}. Best is trial 18 with value: 0.3481561243534088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.192 [ 0.337  0.087]\n",
      "      test loss:  0.250 [ 0.380  0.121]\n",
      "Final result:\n",
      "  train dice loss =  0.3369033932685852\n",
      "  test dice loss =  0.37973618507385254\n",
      "Training Model...\n",
      "  lr    = 0.000915121506827745\n",
      "  gamma = 0.8101507223639411\n",
      "  bsize = 371\n",
      "    * Epoch: 0\n",
      "      train loss:  0.658 [ 0.650  0.672]\n",
      "      test loss:  0.656 [ 0.638  0.673]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.541 [ 0.836  0.605]\n",
      "      test loss:  0.739 [ 0.827  0.651]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.328 [ 0.593  0.418]\n",
      "      test loss:  0.599 [ 0.622  0.575]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.278 [ 0.412  0.164]\n",
      "      test loss:  0.272 [ 0.405  0.139]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.261 [ 0.419  0.138]\n",
      "      test loss:  0.283 [ 0.431  0.135]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.249 [ 0.382  0.129]\n",
      "      test loss:  0.249 [ 0.380  0.118]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.237 [ 0.376  0.122]\n",
      "      test loss:  0.247 [ 0.379  0.116]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.231 [ 0.372  0.116]\n",
      "      test loss:  0.245 [ 0.377  0.114]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.228 [ 0.367  0.113]\n",
      "      test loss:  0.242 [ 0.372  0.112]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 21:11:33,192] Trial 23 finished with value: 0.37369054555892944 and parameters: {'lr': 0.000915121506827745, 'gamma': 0.8101507223639411, 'batch_size': 371}. Best is trial 18 with value: 0.3481561243534088.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.225 [ 0.364  0.111]\n",
      "      test loss:  0.242 [ 0.374  0.110]\n",
      "Final result:\n",
      "  train dice loss =  0.3638046979904175\n",
      "  test dice loss =  0.37369054555892944\n",
      "Training Model...\n",
      "  lr    = 0.0012282809481797968\n",
      "  gamma = 0.9858332489082766\n",
      "  bsize = 271\n",
      "    * Epoch: 0\n",
      "      train loss:  0.711 [ 0.658  0.667]\n",
      "      test loss:  0.655 [ 0.644  0.666]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.468 [ 0.595  0.372]\n",
      "      test loss:  0.422 [ 0.546  0.298]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.290 [ 0.428  0.235]\n",
      "      test loss:  0.298 [ 0.401  0.195]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.258 [ 0.402  0.129]\n",
      "      test loss:  0.257 [ 0.394  0.120]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.239 [ 0.404  0.132]\n",
      "      test loss:  0.267 [ 0.408  0.127]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.228 [ 0.364  0.109]\n",
      "      test loss:  0.245 [ 0.376  0.114]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.217 [ 0.355  0.105]\n",
      "      test loss:  0.238 [ 0.370  0.105]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.209 [ 0.363  0.124]\n",
      "      test loss:  0.260 [ 0.377  0.143]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.207 [ 0.354  0.109]\n",
      "      test loss:  0.257 [ 0.389  0.124]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 21:30:35,131] Trial 24 finished with value: 0.3477874994277954 and parameters: {'lr': 0.0012282809481797968, 'gamma': 0.9858332489082766, 'batch_size': 271}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.206 [ 0.361  0.122]\n",
      "      test loss:  0.234 [ 0.348  0.120]\n",
      "Final result:\n",
      "  train dice loss =  0.36077263951301575\n",
      "  test dice loss =  0.3477874994277954\n",
      "Training Model...\n",
      "  lr    = 0.0005282440325490038\n",
      "  gamma = 0.9012131897499766\n",
      "  bsize = 616\n",
      "    * Epoch: 0\n",
      "      train loss:  0.594 [ 0.776  1.455]\n",
      "      test loss:  1.387 [ 0.811  1.963]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.488 [ 0.620  0.333]\n",
      "      test loss:  0.507 [ 0.640  0.375]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.387 [ 0.558  0.271]\n",
      "      test loss:  0.451 [ 0.576  0.326]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.317 [ 0.482  0.220]\n",
      "      test loss:  0.363 [ 0.480  0.246]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.276 [ 0.439  0.181]\n",
      "      test loss:  0.292 [ 0.418  0.165]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.261 [ 0.424  0.167]\n",
      "      test loss:  0.284 [ 0.409  0.159]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.244 [ 0.393  0.136]\n",
      "      test loss:  0.263 [ 0.388  0.139]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.241 [ 0.381  0.124]\n",
      "      test loss:  0.255 [ 0.380  0.131]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.236 [ 0.387  0.119]\n",
      "      test loss:  0.262 [ 0.389  0.135]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 21:49:44,458] Trial 25 finished with value: 0.3772435486316681 and parameters: {'lr': 0.0005282440325490038, 'gamma': 0.9012131897499766, 'batch_size': 616}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.231 [ 0.374  0.113]\n",
      "      test loss:  0.251 [ 0.377  0.125]\n",
      "Final result:\n",
      "  train dice loss =  0.373526394367218\n",
      "  test dice loss =  0.3772435486316681\n",
      "Training Model...\n",
      "  lr    = 0.0006585604588157679\n",
      "  gamma = 0.7542573647359804\n",
      "  bsize = 291\n",
      "    * Epoch: 0\n",
      "      train loss:  0.605 [ 0.592  0.397]\n",
      "      test loss:  0.462 [ 0.560  0.364]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.379 [ 0.518  0.300]\n",
      "      test loss:  0.354 [ 0.466  0.243]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.279 [ 0.463  0.187]\n",
      "      test loss:  0.329 [ 0.457  0.201]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.246 [ 0.419  0.139]\n",
      "      test loss:  0.281 [ 0.418  0.145]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.238 [ 0.372  0.117]\n",
      "      test loss:  0.242 [ 0.369  0.115]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.228 [ 0.367  0.112]\n",
      "      test loss:  0.243 [ 0.367  0.119]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.223 [ 0.367  0.110]\n",
      "      test loss:  0.245 [ 0.371  0.120]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.220 [ 0.360  0.106]\n",
      "      test loss:  0.241 [ 0.365  0.117]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.218 [ 0.358  0.106]\n",
      "      test loss:  0.241 [ 0.363  0.118]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 22:08:48,011] Trial 26 finished with value: 0.36895519495010376 and parameters: {'lr': 0.0006585604588157679, 'gamma': 0.7542573647359804, 'batch_size': 291}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.217 [ 0.362  0.106]\n",
      "      test loss:  0.244 [ 0.369  0.120]\n",
      "Final result:\n",
      "  train dice loss =  0.36209678649902344\n",
      "  test dice loss =  0.36895519495010376\n",
      "Training Model...\n",
      "  lr    = 0.0011535261476228755\n",
      "  gamma = 0.9129906535744474\n",
      "  bsize = 168\n",
      "    * Epoch: 0\n",
      "      train loss:  0.556 [ 0.774  0.566]\n",
      "      test loss:  0.716 [ 0.783  0.649]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.279 [ 0.410  0.156]\n",
      "      test loss:  0.262 [ 0.392  0.133]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.237 [ 0.466  0.196]\n",
      "      test loss:  0.337 [ 0.470  0.204]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.232 [ 0.364  0.111]\n",
      "      test loss:  0.237 [ 0.362  0.111]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.214 [ 0.356  0.116]\n",
      "      test loss:  0.242 [ 0.363  0.121]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.215 [ 0.357  0.106]\n",
      "      test loss:  0.255 [ 0.389  0.120]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.206 [ 0.342  0.092]\n",
      "      test loss:  0.227 [ 0.353  0.100]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.201 [ 0.338  0.090]\n",
      "      test loss:  0.232 [ 0.355  0.110]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.196 [ 0.337  0.090]\n",
      "      test loss:  0.234 [ 0.357  0.111]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 22:28:01,100] Trial 27 finished with value: 0.36680442094802856 and parameters: {'lr': 0.0011535261476228755, 'gamma': 0.9129906535744474, 'batch_size': 168}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.196 [ 0.336  0.083]\n",
      "      test loss:  0.240 [ 0.367  0.113]\n",
      "Final result:\n",
      "  train dice loss =  0.33570432662963867\n",
      "  test dice loss =  0.36680442094802856\n",
      "Training Model...\n",
      "  lr    = 0.0012673490710451273\n",
      "  gamma = 0.9985422638184627\n",
      "  bsize = 560\n",
      "    * Epoch: 0\n",
      "      train loss:  1.074 [ 0.655  0.704]\n",
      "      test loss:  0.674 [ 0.644  0.703]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.644 [ 0.634  0.669]\n",
      "      test loss:  0.650 [ 0.625  0.675]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.568 [ 0.612  0.523]\n",
      "      test loss:  0.569 [ 0.597  0.540]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.440 [ 0.897  5.792]\n",
      "      test loss:  5.076 [ 0.933  9.218]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.344 [ 0.851  1.487]\n",
      "      test loss:  1.511 [ 0.858  2.163]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.302 [ 0.461  0.249]\n",
      "      test loss:  0.406 [ 0.466  0.345]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.272 [ 0.419  0.169]\n",
      "      test loss:  0.279 [ 0.397  0.161]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.256 [ 0.428  0.201]\n",
      "      test loss:  0.279 [ 0.393  0.165]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.243 [ 0.421  0.190]\n",
      "      test loss:  0.273 [ 0.388  0.158]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 22:47:05,421] Trial 28 finished with value: 0.36314311623573303 and parameters: {'lr': 0.0012673490710451273, 'gamma': 0.9985422638184627, 'batch_size': 560}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.234 [ 0.379  0.136]\n",
      "      test loss:  0.241 [ 0.363  0.118]\n",
      "Final result:\n",
      "  train dice loss =  0.3792303800582886\n",
      "  test dice loss =  0.36314311623573303\n",
      "Training Model...\n",
      "  lr    = 0.0003678161483053271\n",
      "  gamma = 0.8563965158389422\n",
      "  bsize = 438\n",
      "    * Epoch: 0\n",
      "      train loss:  0.565 [ 0.744  0.639]\n",
      "      test loss:  0.841 [ 0.783  0.898]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.449 [ 0.554  0.284]\n",
      "      test loss:  0.428 [ 0.559  0.297]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.363 [ 0.484  0.221]\n",
      "      test loss:  0.369 [ 0.482  0.255]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.313 [ 0.448  0.186]\n",
      "      test loss:  0.309 [ 0.442  0.176]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.282 [ 0.425  0.161]\n",
      "      test loss:  0.290 [ 0.425  0.155]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.261 [ 0.402  0.145]\n",
      "      test loss:  0.274 [ 0.404  0.144]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.248 [ 0.384  0.126]\n",
      "      test loss:  0.257 [ 0.385  0.129]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.241 [ 0.380  0.119]\n",
      "      test loss:  0.255 [ 0.384  0.126]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.234 [ 0.374  0.115]\n",
      "      test loss:  0.253 [ 0.382  0.124]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 23:08:50,990] Trial 29 finished with value: 0.3805682361125946 and parameters: {'lr': 0.0003678161483053271, 'gamma': 0.8563965158389422, 'batch_size': 438}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.229 [ 0.370  0.112]\n",
      "      test loss:  0.252 [ 0.381  0.123]\n",
      "Final result:\n",
      "  train dice loss =  0.3704523742198944\n",
      "  test dice loss =  0.3805682361125946\n",
      "Training Model...\n",
      "  lr    = 0.0008725341276262948\n",
      "  gamma = 0.6724361133202044\n",
      "  bsize = 289\n",
      "    * Epoch: 0\n",
      "      train loss:  0.661 [ 0.610  0.595]\n",
      "      test loss:  0.606 [ 0.602  0.609]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.440 [ 0.638  0.364]\n",
      "      test loss:  0.556 [ 0.655  0.457]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.322 [ 0.463  0.192]\n",
      "      test loss:  0.338 [ 0.456  0.219]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.274 [ 0.412  0.147]\n",
      "      test loss:  0.271 [ 0.399  0.143]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.255 [ 0.394  0.133]\n",
      "      test loss:  0.255 [ 0.386  0.125]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.245 [ 0.385  0.125]\n",
      "      test loss:  0.253 [ 0.382  0.124]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.240 [ 0.379  0.122]\n",
      "      test loss:  0.250 [ 0.379  0.121]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.238 [ 0.380  0.119]\n",
      "      test loss:  0.253 [ 0.383  0.124]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.236 [ 0.376  0.119]\n",
      "      test loss:  0.248 [ 0.375  0.121]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 23:34:30,631] Trial 30 finished with value: 0.3745945990085602 and parameters: {'lr': 0.0008725341276262948, 'gamma': 0.6724361133202044, 'batch_size': 289}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.233 [ 0.375  0.118]\n",
      "      test loss:  0.248 [ 0.375  0.121]\n",
      "Final result:\n",
      "  train dice loss =  0.37478867173194885\n",
      "  test dice loss =  0.3745945990085602\n",
      "Training Model...\n",
      "  lr    = 0.0016151169061354106\n",
      "  gamma = 0.9627959620273312\n",
      "  bsize = 66\n",
      "    * Epoch: 0\n",
      "      train loss:  0.439 [ 0.413  0.164]\n",
      "      test loss:  0.271 [ 0.404  0.137]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.249 [ 0.399  0.150]\n",
      "      test loss:  0.253 [ 0.371  0.134]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.226 [ 0.367  0.116]\n",
      "      test loss:  0.239 [ 0.358  0.120]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.210 [ 0.346  0.104]\n",
      "      test loss:  0.229 [ 0.349  0.109]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.200 [ 0.336  0.088]\n",
      "      test loss:  0.231 [ 0.358  0.105]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.198 [ 0.351  0.110]\n",
      "      test loss:  0.242 [ 0.355  0.130]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.195 [ 0.331  0.086]\n",
      "      test loss:  0.231 [ 0.356  0.106]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.187 [ 0.329  0.091]\n",
      "      test loss:  0.236 [ 0.351  0.121]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.183 [ 0.321  0.073]\n",
      "      test loss:  0.243 [ 0.369  0.117]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-22 23:53:40,680] Trial 31 finished with value: 0.3966233730316162 and parameters: {'lr': 0.0016151169061354106, 'gamma': 0.9627959620273312, 'batch_size': 66}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.180 [ 0.329  0.074]\n",
      "      test loss:  0.267 [ 0.397  0.137]\n",
      "Final result:\n",
      "  train dice loss =  0.32860010862350464\n",
      "  test dice loss =  0.3966233730316162\n",
      "Training Model...\n",
      "  lr    = 0.0014167480236545091\n",
      "  gamma = 0.8996022995726682\n",
      "  bsize = 207\n",
      "    * Epoch: 0\n",
      "      train loss:  0.739 [ 0.636  0.648]\n",
      "      test loss:  0.639 [ 0.625  0.652]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.443 [ 0.526  0.266]\n",
      "      test loss:  0.416 [ 0.533  0.298]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.292 [ 0.457  0.184]\n",
      "      test loss:  0.309 [ 0.448  0.171]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.247 [ 0.391  0.123]\n",
      "      test loss:  0.261 [ 0.393  0.129]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.233 [ 0.376  0.121]\n",
      "      test loss:  0.249 [ 0.368  0.129]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.238 [ 0.369  0.116]\n",
      "      test loss:  0.246 [ 0.366  0.126]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.222 [ 0.362  0.110]\n",
      "      test loss:  0.235 [ 0.359  0.112]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.213 [ 0.353  0.104]\n",
      "      test loss:  0.229 [ 0.349  0.109]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.208 [ 0.349  0.095]\n",
      "      test loss:  0.242 [ 0.370  0.114]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 00:12:43,629] Trial 32 finished with value: 0.35590580105781555 and parameters: {'lr': 0.0014167480236545091, 'gamma': 0.8996022995726682, 'batch_size': 207}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.205 [ 0.343  0.094]\n",
      "      test loss:  0.233 [ 0.356  0.111]\n",
      "Final result:\n",
      "  train dice loss =  0.34336617588996887\n",
      "  test dice loss =  0.35590580105781555\n",
      "Training Model...\n",
      "  lr    = 0.0022677266083884354\n",
      "  gamma = 0.9577234203934851\n",
      "  bsize = 1017\n",
      "    * Epoch: 0\n",
      "      train loss:  5.426 [ 0.657  0.771]\n",
      "      test loss:  0.719 [ 0.652  0.786]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.652 [ 0.643  0.680]\n",
      "      test loss:  0.656 [ 0.633  0.680]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.602 [ 0.595  0.630]\n",
      "      test loss:  0.592 [ 0.575  0.609]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.510 [ 0.728  0.484]\n",
      "      test loss:  0.591 [ 0.701  0.480]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.372 [ 0.812  0.690]\n",
      "      test loss:  0.788 [ 0.793  0.783]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.327 [ 0.577  0.376]\n",
      "      test loss:  0.508 [ 0.573  0.443]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.306 [ 0.538  0.301]\n",
      "      test loss:  0.482 [ 0.548  0.415]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.286 [ 0.461  0.208]\n",
      "      test loss:  0.339 [ 0.453  0.225]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.279 [ 0.429  0.185]\n",
      "      test loss:  0.284 [ 0.403  0.164]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 00:32:59,691] Trial 33 finished with value: 0.41275179386138916 and parameters: {'lr': 0.0022677266083884354, 'gamma': 0.9577234203934851, 'batch_size': 1017}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.272 [ 0.431  0.168]\n",
      "      test loss:  0.282 [ 0.413  0.150]\n",
      "Final result:\n",
      "  train dice loss =  0.43066537380218506\n",
      "  test dice loss =  0.41275179386138916\n",
      "Training Model...\n",
      "  lr    = 0.0017622459425663609\n",
      "  gamma = 0.8135233405633857\n",
      "  bsize = 399\n",
      "    * Epoch: 0\n",
      "      train loss:  2.031 [ 0.630  0.696]\n",
      "      test loss:  0.659 [ 0.619  0.699]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.593 [ 0.655  0.685]\n",
      "      test loss:  0.663 [ 0.642  0.684]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.531 [ 0.650  0.529]\n",
      "      test loss:  0.574 [ 0.624  0.523]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.407 [ 0.534  0.273]\n",
      "      test loss:  0.373 [ 0.498  0.247]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.305 [ 0.444  0.183]\n",
      "      test loss:  0.293 [ 0.431  0.154]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.276 [ 0.454  0.171]\n",
      "      test loss:  0.309 [ 0.449  0.169]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.265 [ 0.425  0.149]\n",
      "      test loss:  0.284 [ 0.423  0.144]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.252 [ 0.396  0.133]\n",
      "      test loss:  0.262 [ 0.391  0.132]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.246 [ 0.387  0.132]\n",
      "      test loss:  0.251 [ 0.377  0.125]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 00:52:33,645] Trial 34 finished with value: 0.3709142208099365 and parameters: {'lr': 0.0017622459425663609, 'gamma': 0.8135233405633857, 'batch_size': 399}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.242 [ 0.385  0.134]\n",
      "      test loss:  0.248 [ 0.371  0.125]\n",
      "Final result:\n",
      "  train dice loss =  0.3849841058254242\n",
      "  test dice loss =  0.3709142208099365\n",
      "Training Model...\n",
      "  lr    = 0.0015060792342590865\n",
      "  gamma = 0.9467404783442613\n",
      "  bsize = 65\n",
      "    * Epoch: 0\n",
      "      train loss:  0.430 [ 0.404  0.157]\n",
      "      test loss:  0.259 [ 0.381  0.137]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.261 [ 0.384  0.131]\n",
      "      test loss:  0.248 [ 0.368  0.127]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.230 [ 0.360  0.117]\n",
      "      test loss:  0.235 [ 0.359  0.111]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.216 [ 0.360  0.102]\n",
      "      test loss:  0.259 [ 0.394  0.124]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.201 [ 0.340  0.100]\n",
      "      test loss:  0.298 [ 0.366  0.229]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.202 [ 0.375  0.191]\n",
      "      test loss:  0.303 [ 0.412  0.195]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.202 [ 0.334  0.092]\n",
      "      test loss:  0.233 [ 0.362  0.105]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.193 [ 0.327  0.080]\n",
      "      test loss:  0.217 [ 0.333  0.101]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.186 [ 0.323  0.076]\n",
      "      test loss:  0.219 [ 0.338  0.101]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 01:11:51,525] Trial 35 finished with value: 0.37580323219299316 and parameters: {'lr': 0.0015060792342590865, 'gamma': 0.9467404783442613, 'batch_size': 65}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.185 [ 0.331  0.080]\n",
      "      test loss:  0.253 [ 0.376  0.130]\n",
      "Final result:\n",
      "  train dice loss =  0.33140280842781067\n",
      "  test dice loss =  0.37580323219299316\n",
      "Training Model...\n",
      "  lr    = 0.0012751187802064192\n",
      "  gamma = 0.998002184172888\n",
      "  bsize = 284\n",
      "    * Epoch: 0\n",
      "      train loss:  0.800 [ 0.622  0.654]\n",
      "      test loss:  0.647 [ 0.620  0.675]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.521 [ 0.601  0.426]\n",
      "      test loss:  0.510 [ 0.582  0.437]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.313 [ 0.417  0.202]\n",
      "      test loss:  0.292 [ 0.391  0.192]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.281 [ 0.408  0.161]\n",
      "      test loss:  0.266 [ 0.401  0.132]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.251 [ 0.399  0.125]\n",
      "      test loss:  0.266 [ 0.396  0.137]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.236 [ 0.394  0.138]\n",
      "      test loss:  0.255 [ 0.390  0.120]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.224 [ 0.364  0.117]\n",
      "      test loss:  0.234 [ 0.358  0.110]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.217 [ 0.368  0.117]\n",
      "      test loss:  0.245 [ 0.370  0.119]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.216 [ 0.354  0.111]\n",
      "      test loss:  0.231 [ 0.355  0.107]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 01:30:53,149] Trial 36 finished with value: 0.353898286819458 and parameters: {'lr': 0.0012751187802064192, 'gamma': 0.998002184172888, 'batch_size': 284}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.212 [ 0.349  0.098]\n",
      "      test loss:  0.232 [ 0.354  0.109]\n",
      "Final result:\n",
      "  train dice loss =  0.3487030565738678\n",
      "  test dice loss =  0.353898286819458\n",
      "Training Model...\n",
      "  lr    = 0.001267343743431459\n",
      "  gamma = 0.8891058270615406\n",
      "  bsize = 281\n",
      "    * Epoch: 0\n",
      "      train loss:  0.707 [ 0.612  0.679]\n",
      "      test loss:  0.647 [ 0.606  0.688]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.514 [ 0.771  0.566]\n",
      "      test loss:  0.657 [ 0.747  0.566]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.327 [ 0.542  0.303]\n",
      "      test loss:  0.405 [ 0.528  0.282]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.274 [ 0.421  0.152]\n",
      "      test loss:  0.277 [ 0.419  0.136]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.258 [ 0.399  0.150]\n",
      "      test loss:  0.262 [ 0.376  0.148]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.245 [ 0.395  0.145]\n",
      "      test loss:  0.244 [ 0.368  0.120]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.238 [ 0.382  0.129]\n",
      "      test loss:  0.240 [ 0.363  0.117]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.230 [ 0.371  0.113]\n",
      "      test loss:  0.238 [ 0.366  0.111]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.222 [ 0.366  0.109]\n",
      "      test loss:  0.242 [ 0.369  0.115]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 01:49:56,136] Trial 37 finished with value: 0.3589378893375397 and parameters: {'lr': 0.001267343743431459, 'gamma': 0.8891058270615406, 'batch_size': 281}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.217 [ 0.359  0.104]\n",
      "      test loss:  0.233 [ 0.359  0.107]\n",
      "Final result:\n",
      "  train dice loss =  0.35905128717422485\n",
      "  test dice loss =  0.3589378893375397\n",
      "Training Model...\n",
      "  lr    = 0.00018092184785920376\n",
      "  gamma = 0.9259006153565172\n",
      "  bsize = 509\n",
      "    * Epoch: 0\n",
      "      train loss:  0.626 [ 0.642  0.398]\n",
      "      test loss:  0.519 [ 0.638  0.399]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.438 [ 0.714  0.411]\n",
      "      test loss:  0.568 [ 0.704  0.432]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.414 [ 0.604  0.258]\n",
      "      test loss:  0.405 [ 0.575  0.235]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.374 [ 0.524  0.226]\n",
      "      test loss:  0.354 [ 0.503  0.205]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.350 [ 0.491  0.219]\n",
      "      test loss:  0.330 [ 0.463  0.197]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.327 [ 0.463  0.189]\n",
      "      test loss:  0.310 [ 0.442  0.178]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.305 [ 0.469  0.172]\n",
      "      test loss:  0.324 [ 0.459  0.189]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.290 [ 0.442  0.157]\n",
      "      test loss:  0.303 [ 0.434  0.172]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.273 [ 0.416  0.145]\n",
      "      test loss:  0.280 [ 0.409  0.151]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 02:08:57,510] Trial 38 finished with value: 0.403737336397171 and parameters: {'lr': 0.00018092184785920376, 'gamma': 0.9259006153565172, 'batch_size': 509}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.262 [ 0.406  0.137]\n",
      "      test loss:  0.274 [ 0.404  0.145]\n",
      "Final result:\n",
      "  train dice loss =  0.40614959597587585\n",
      "  test dice loss =  0.403737336397171\n",
      "Training Model...\n",
      "  lr    = 0.00101395733124608\n",
      "  gamma = 0.46618144646487597\n",
      "  bsize = 417\n",
      "    * Epoch: 0\n",
      "      train loss:  0.690 [ 0.648  0.720]\n",
      "      test loss:  0.680 [ 0.638  0.721]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.642 [ 0.622  0.681]\n",
      "      test loss:  0.651 [ 0.614  0.688]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.599 [ 0.628  0.652]\n",
      "      test loss:  0.638 [ 0.618  0.659]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.566 [ 0.605  0.605]\n",
      "      test loss:  0.610 [ 0.598  0.621]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.548 [ 0.586  0.571]\n",
      "      test loss:  0.576 [ 0.574  0.577]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.538 [ 0.579  0.556]\n",
      "      test loss:  0.558 [ 0.564  0.551]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.532 [ 0.576  0.548]\n",
      "      test loss:  0.550 [ 0.560  0.539]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.529 [ 0.575  0.544]\n",
      "      test loss:  0.546 [ 0.559  0.534]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.527 [ 0.574  0.543]\n",
      "      test loss:  0.544 [ 0.558  0.531]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 02:28:00,332] Trial 39 finished with value: 0.5566310882568359 and parameters: {'lr': 0.00101395733124608, 'gamma': 0.46618144646487597, 'batch_size': 417}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.527 [ 0.573  0.543]\n",
      "      test loss:  0.543 [ 0.557  0.530]\n",
      "Final result:\n",
      "  train dice loss =  0.5734946727752686\n",
      "  test dice loss =  0.5566310882568359\n",
      "Training Model...\n",
      "  lr    = 0.000721840430402092\n",
      "  gamma = 0.6945817869085382\n",
      "  bsize = 161\n",
      "    * Epoch: 0\n",
      "      train loss:  0.547 [ 0.624  0.461]\n",
      "      test loss:  0.765 [ 0.673  0.857]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.274 [ 0.453  0.157]\n",
      "      test loss:  0.317 [ 0.455  0.180]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.255 [ 0.376  0.115]\n",
      "      test loss:  0.250 [ 0.381  0.120]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.228 [ 0.363  0.111]\n",
      "      test loss:  0.243 [ 0.367  0.118]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.220 [ 0.359  0.104]\n",
      "      test loss:  0.246 [ 0.372  0.119]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.217 [ 0.360  0.102]\n",
      "      test loss:  0.251 [ 0.376  0.126]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.217 [ 0.353  0.101]\n",
      "      test loss:  0.242 [ 0.367  0.117]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.214 [ 0.353  0.098]\n",
      "      test loss:  0.243 [ 0.366  0.120]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.212 [ 0.351  0.098]\n",
      "      test loss:  0.243 [ 0.366  0.120]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 02:47:09,437] Trial 40 finished with value: 0.36673998832702637 and parameters: {'lr': 0.000721840430402092, 'gamma': 0.6945817869085382, 'batch_size': 161}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.210 [ 0.350  0.098]\n",
      "      test loss:  0.244 [ 0.367  0.120]\n",
      "Final result:\n",
      "  train dice loss =  0.3502368927001953\n",
      "  test dice loss =  0.36673998832702637\n",
      "Training Model...\n",
      "  lr    = 0.0018769253009069066\n",
      "  gamma = 0.9741499350778152\n",
      "  bsize = 263\n",
      "    * Epoch: 0\n",
      "      train loss:  1.611 [ 0.621  0.669]\n",
      "      test loss:  0.644 [ 0.613  0.675]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.509 [ 0.806  0.720]\n",
      "      test loss:  0.841 [ 0.824  0.859]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.302 [ 0.505  0.246]\n",
      "      test loss:  0.385 [ 0.497  0.273]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.266 [ 0.398  0.148]\n",
      "      test loss:  0.253 [ 0.378  0.128]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.250 [ 0.386  0.130]\n",
      "      test loss:  0.252 [ 0.378  0.127]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.235 [ 0.391  0.135]\n",
      "      test loss:  0.265 [ 0.392  0.139]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.231 [ 0.373  0.118]\n",
      "      test loss:  0.244 [ 0.368  0.120]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.223 [ 0.372  0.130]\n",
      "      test loss:  0.246 [ 0.367  0.124]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.218 [ 0.356  0.105]\n",
      "      test loss:  0.229 [ 0.353  0.105]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 03:07:01,615] Trial 41 finished with value: 0.3511042296886444 and parameters: {'lr': 0.0018769253009069066, 'gamma': 0.9741499350778152, 'batch_size': 263}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.212 [ 0.356  0.107]\n",
      "      test loss:  0.228 [ 0.351  0.106]\n",
      "Final result:\n",
      "  train dice loss =  0.35560348629951477\n",
      "  test dice loss =  0.3511042296886444\n",
      "Training Model...\n",
      "  lr    = 0.0018754077102106901\n",
      "  gamma = 0.999334428697175\n",
      "  bsize = 276\n",
      "    * Epoch: 0\n",
      "      train loss:  1.783 [ 0.925 11.938]\n",
      "      test loss: 10.870 [ 0.949 20.792]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.420 [ 0.773  4.123]\n",
      "      test loss:  7.031 [ 0.880 13.182]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.313 [ 0.429  0.195]\n",
      "      test loss:  0.311 [ 0.417  0.204]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.278 [ 0.411  0.152]\n",
      "      test loss:  0.275 [ 0.408  0.142]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.255 [ 0.395  0.145]\n",
      "      test loss:  0.248 [ 0.374  0.122]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.243 [ 0.388  0.133]\n",
      "      test loss:  0.268 [ 0.401  0.134]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.236 [ 0.387  0.139]\n",
      "      test loss:  0.249 [ 0.372  0.127]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.231 [ 0.370  0.115]\n",
      "      test loss:  0.249 [ 0.385  0.113]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.226 [ 0.361  0.112]\n",
      "      test loss:  0.242 [ 0.369  0.116]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 03:27:35,189] Trial 42 finished with value: 0.37140873074531555 and parameters: {'lr': 0.0018754077102106901, 'gamma': 0.999334428697175, 'batch_size': 276}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.220 [ 0.356  0.109]\n",
      "      test loss:  0.241 [ 0.371  0.111]\n",
      "Final result:\n",
      "  train dice loss =  0.3555108606815338\n",
      "  test dice loss =  0.37140873074531555\n",
      "Training Model...\n",
      "  lr    = 0.002208975778576809\n",
      "  gamma = 0.9545895944230662\n",
      "  bsize = 900\n",
      "    * Epoch: 0\n",
      "      train loss:  2.132 [ 0.665 70.646]\n",
      "      test loss: 29.001 [ 0.656 57.346]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.924 [ 0.674  1.593]\n",
      "      test loss:  1.094 [ 0.672  1.517]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.629 [ 0.638  0.632]\n",
      "      test loss:  0.634 [ 0.628  0.639]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.579 [ 0.580  0.442]\n",
      "      test loss:  0.517 [ 0.568  0.465]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.408 [ 0.540  0.307]\n",
      "      test loss:  0.473 [ 0.554  0.392]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.318 [ 0.748  0.888]\n",
      "      test loss:  0.775 [ 0.719  0.831]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.341 [ 0.506  0.321]\n",
      "      test loss:  0.392 [ 0.488  0.296]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.296 [ 0.426  0.170]\n",
      "      test loss:  0.281 [ 0.418  0.145]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.285 [ 0.435  0.173]\n",
      "      test loss:  0.277 [ 0.405  0.149]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 03:48:39,030] Trial 43 finished with value: 0.3906238079071045 and parameters: {'lr': 0.002208975778576809, 'gamma': 0.9545895944230662, 'batch_size': 900}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.270 [ 0.407  0.149]\n",
      "      test loss:  0.256 [ 0.391  0.122]\n",
      "Final result:\n",
      "  train dice loss =  0.4069370925426483\n",
      "  test dice loss =  0.3906238079071045\n",
      "Training Model...\n",
      "  lr    = 0.0019240361287798271\n",
      "  gamma = 0.8435055877735449\n",
      "  bsize = 345\n",
      "    * Epoch: 0\n",
      "      train loss:  1.340 [ 0.633  0.615]\n",
      "      test loss:  0.622 [ 0.623  0.622]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.472 [ 0.826  0.679]\n",
      "      test loss:  0.760 [ 0.831  0.690]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.334 [ 0.566  0.360]\n",
      "      test loss:  0.510 [ 0.556  0.464]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.286 [ 0.518  0.235]\n",
      "      test loss:  0.383 [ 0.506  0.260]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.270 [ 0.409  0.152]\n",
      "      test loss:  0.269 [ 0.398  0.141]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.258 [ 0.417  0.152]\n",
      "      test loss:  0.275 [ 0.407  0.143]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.250 [ 0.398  0.140]\n",
      "      test loss:  0.255 [ 0.383  0.128]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.245 [ 0.389  0.135]\n",
      "      test loss:  0.248 [ 0.376  0.120]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.239 [ 0.386  0.129]\n",
      "      test loss:  0.245 [ 0.374  0.116]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 04:08:20,493] Trial 44 finished with value: 0.3674469590187073 and parameters: {'lr': 0.0019240361287798271, 'gamma': 0.8435055877735449, 'batch_size': 345}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.235 [ 0.380  0.126]\n",
      "      test loss:  0.239 [ 0.367  0.111]\n",
      "Final result:\n",
      "  train dice loss =  0.38014400005340576\n",
      "  test dice loss =  0.3674469590187073\n",
      "Training Model...\n",
      "  lr    = 0.002154392990790685\n",
      "  gamma = 0.934489224049005\n",
      "  bsize = 493\n",
      "    * Epoch: 0\n",
      "      train loss:  1.733 [ 0.660  5.464]\n",
      "      test loss:  2.867 [ 0.649  5.085]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.629 [ 0.636  0.691]\n",
      "      test loss:  0.659 [ 0.625  0.693]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.561 [ 0.606  0.380]\n",
      "      test loss:  0.552 [ 0.623  0.482]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.375 [ 0.791  0.904]\n",
      "      test loss:  1.175 [ 0.818  1.532]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.302 [ 0.507  0.282]\n",
      "      test loss:  0.431 [ 0.511  0.351]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.271 [ 0.420  0.160]\n",
      "      test loss:  0.283 [ 0.410  0.157]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.257 [ 0.398  0.145]\n",
      "      test loss:  0.256 [ 0.380  0.133]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.245 [ 0.411  0.169]\n",
      "      test loss:  0.269 [ 0.386  0.152]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.238 [ 0.383  0.131]\n",
      "      test loss:  0.252 [ 0.374  0.130]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 04:28:06,242] Trial 45 finished with value: 0.381732314825058 and parameters: {'lr': 0.002154392990790685, 'gamma': 0.934489224049005, 'batch_size': 493}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.233 [ 0.386  0.133]\n",
      "      test loss:  0.262 [ 0.382  0.143]\n",
      "Final result:\n",
      "  train dice loss =  0.38562166690826416\n",
      "  test dice loss =  0.381732314825058\n",
      "Training Model...\n",
      "  lr    = 0.0013178285559914274\n",
      "  gamma = 0.96963504345267\n",
      "  bsize = 250\n",
      "    * Epoch: 0\n",
      "      train loss:  0.765 [ 0.634  0.643]\n",
      "      test loss:  0.639 [ 0.625  0.653]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.463 [ 0.853  0.717]\n",
      "      test loss:  0.903 [ 0.854  0.953]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.300 [ 0.447  0.246]\n",
      "      test loss:  0.301 [ 0.406  0.196]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.257 [ 0.411  0.173]\n",
      "      test loss:  0.272 [ 0.383  0.161]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.242 [ 0.394  0.145]\n",
      "      test loss:  0.245 [ 0.359  0.131]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.239 [ 0.370  0.121]\n",
      "      test loss:  0.237 [ 0.361  0.114]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.241 [ 0.386  0.149]\n",
      "      test loss:  0.249 [ 0.367  0.130]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.226 [ 0.369  0.115]\n",
      "      test loss:  0.238 [ 0.362  0.114]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.219 [ 0.358  0.108]\n",
      "      test loss:  0.234 [ 0.363  0.105]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 04:47:12,909] Trial 46 finished with value: 0.35607200860977173 and parameters: {'lr': 0.0013178285559914274, 'gamma': 0.96963504345267, 'batch_size': 250}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.215 [ 0.353  0.103]\n",
      "      test loss:  0.231 [ 0.356  0.107]\n",
      "Final result:\n",
      "  train dice loss =  0.3529601991176605\n",
      "  test dice loss =  0.35607200860977173\n",
      "Training Model...\n",
      "  lr    = 0.0024402434928422582\n",
      "  gamma = 0.8885353805286381\n",
      "  bsize = 191\n",
      "    * Epoch: 0\n",
      "      train loss:  2.187 [ 0.620  0.534]\n",
      "      test loss:  0.579 [ 0.608  0.549]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.348 [ 0.523  0.339]\n",
      "      test loss:  0.461 [ 0.518  0.403]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.274 [ 0.429  0.209]\n",
      "      test loss:  0.293 [ 0.400  0.186]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.256 [ 0.398  0.158]\n",
      "      test loss:  0.248 [ 0.372  0.125]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.243 [ 0.383  0.139]\n",
      "      test loss:  0.242 [ 0.369  0.114]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.233 [ 0.370  0.128]\n",
      "      test loss:  0.236 [ 0.364  0.109]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.226 [ 0.373  0.125]\n",
      "      test loss:  0.241 [ 0.363  0.119]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.221 [ 0.363  0.114]\n",
      "      test loss:  0.244 [ 0.365  0.123]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.217 [ 0.361  0.116]\n",
      "      test loss:  0.242 [ 0.363  0.122]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 05:06:52,935] Trial 47 finished with value: 0.36059698462486267 and parameters: {'lr': 0.0024402434928422582, 'gamma': 0.8885353805286381, 'batch_size': 191}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.216 [ 0.358  0.114]\n",
      "      test loss:  0.236 [ 0.361  0.112]\n",
      "Final result:\n",
      "  train dice loss =  0.3575226962566376\n",
      "  test dice loss =  0.36059698462486267\n",
      "Training Model...\n",
      "  lr    = 0.0017650202256422572\n",
      "  gamma = 0.7822804421891297\n",
      "  bsize = 309\n",
      "    * Epoch: 0\n",
      "      train loss:  1.552 [ 0.953  2.812]\n",
      "      test loss:  1.624 [ 0.938  2.310]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.442 [ 0.846  2.727]\n",
      "      test loss:  1.995 [ 0.894  3.096]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.317 [ 0.477  0.187]\n",
      "      test loss:  0.311 [ 0.447  0.175]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.271 [ 0.410  0.146]\n",
      "      test loss:  0.276 [ 0.411  0.142]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.257 [ 0.412  0.185]\n",
      "      test loss:  0.272 [ 0.384  0.159]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.248 [ 0.393  0.144]\n",
      "      test loss:  0.252 [ 0.375  0.129]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.241 [ 0.384  0.134]\n",
      "      test loss:  0.247 [ 0.372  0.122]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.234 [ 0.373  0.120]\n",
      "      test loss:  0.245 [ 0.371  0.120]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.229 [ 0.369  0.116]\n",
      "      test loss:  0.244 [ 0.371  0.117]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 05:26:04,253] Trial 48 finished with value: 0.37089017033576965 and parameters: {'lr': 0.0017650202256422572, 'gamma': 0.7822804421891297, 'batch_size': 309}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.225 [ 0.367  0.113]\n",
      "      test loss:  0.244 [ 0.371  0.117]\n",
      "Final result:\n",
      "  train dice loss =  0.36674830317497253\n",
      "  test dice loss =  0.37089017033576965\n",
      "Training Model...\n",
      "  lr    = 0.002085435798311082\n",
      "  gamma = 0.9694733923844978\n",
      "  bsize = 391\n",
      "    * Epoch: 0\n",
      "      train loss:  3.032 [ 0.617  0.655]\n",
      "      test loss:  0.635 [ 0.612  0.658]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.524 [ 0.590  0.439]\n",
      "      test loss:  0.662 [ 0.637  0.688]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.332 [ 0.840  0.959]\n",
      "      test loss:  0.941 [ 0.830  1.052]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.320 [ 0.469  0.194]\n",
      "      test loss:  0.312 [ 0.446  0.178]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.280 [ 0.431  0.165]\n",
      "      test loss:  0.283 [ 0.418  0.147]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.264 [ 0.423  0.198]\n",
      "      test loss:  0.285 [ 0.387  0.183]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.271 [ 0.399  0.150]\n",
      "      test loss:  0.262 [ 0.390  0.135]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.246 [ 0.395  0.147]\n",
      "      test loss:  0.250 [ 0.372  0.127]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.237 [ 0.384  0.133]\n",
      "      test loss:  0.242 [ 0.372  0.113]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 05:46:25,679] Trial 49 finished with value: 0.367489218711853 and parameters: {'lr': 0.002085435798311082, 'gamma': 0.9694733923844978, 'batch_size': 391}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.230 [ 0.378  0.119]\n",
      "      test loss:  0.240 [ 0.367  0.112]\n",
      "Final result:\n",
      "  train dice loss =  0.3778596520423889\n",
      "  test dice loss =  0.367489218711853\n",
      "Training Model...\n",
      "  lr    = 0.0011431701864491575\n",
      "  gamma = 0.5611937600502825\n",
      "  bsize = 246\n",
      "    * Epoch: 0\n",
      "      train loss:  0.676 [ 0.640  0.661]\n",
      "      test loss:  0.630 [ 0.624  0.637]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.461 [ 0.509  0.262]\n",
      "      test loss:  0.424 [ 0.522  0.327]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.291 [ 0.429  0.155]\n",
      "      test loss:  0.295 [ 0.430  0.159]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.258 [ 0.409  0.133]\n",
      "      test loss:  0.275 [ 0.414  0.136]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.246 [ 0.389  0.126]\n",
      "      test loss:  0.259 [ 0.390  0.128]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.240 [ 0.385  0.122]\n",
      "      test loss:  0.256 [ 0.386  0.125]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.238 [ 0.380  0.124]\n",
      "      test loss:  0.248 [ 0.375  0.121]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.237 [ 0.380  0.120]\n",
      "      test loss:  0.251 [ 0.379  0.123]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.236 [ 0.378  0.120]\n",
      "      test loss:  0.248 [ 0.376  0.121]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 06:05:30,096] Trial 50 finished with value: 0.3763362467288971 and parameters: {'lr': 0.0011431701864491575, 'gamma': 0.5611937600502825, 'batch_size': 246}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.235 [ 0.378  0.119]\n",
      "      test loss:  0.249 [ 0.376  0.121]\n",
      "Final result:\n",
      "  train dice loss =  0.37753066420555115\n",
      "  test dice loss =  0.3763362467288971\n",
      "Training Model...\n",
      "  lr    = 0.001497178567482522\n",
      "  gamma = 0.9812083462140174\n",
      "  bsize = 65\n",
      "    * Epoch: 0\n",
      "      train loss:  0.436 [ 0.435  0.278]\n",
      "      test loss:  0.309 [ 0.390  0.227]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.238 [ 0.362  0.109]\n",
      "      test loss:  0.246 [ 0.369  0.122]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.227 [ 0.379  0.133]\n",
      "      test loss:  0.263 [ 0.369  0.156]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.224 [ 0.357  0.111]\n",
      "      test loss:  0.246 [ 0.367  0.126]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.223 [ 0.397  0.139]\n",
      "      test loss:  0.290 [ 0.429  0.151]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.207 [ 0.338  0.090]\n",
      "      test loss:  0.240 [ 0.364  0.115]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.202 [ 0.337  0.090]\n",
      "      test loss:  0.229 [ 0.346  0.113]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.193 [ 0.330  0.084]\n",
      "      test loss:  0.243 [ 0.373  0.113]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.188 [ 0.326  0.079]\n",
      "      test loss:  0.228 [ 0.353  0.103]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 06:24:46,730] Trial 51 finished with value: 0.46049171686172485 and parameters: {'lr': 0.001497178567482522, 'gamma': 0.9812083462140174, 'batch_size': 65}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.184 [ 0.403  0.310]\n",
      "      test loss:  0.413 [ 0.460  0.366]\n",
      "Final result:\n",
      "  train dice loss =  0.40293774008750916\n",
      "  test dice loss =  0.46049171686172485\n",
      "Training Model...\n",
      "  lr    = 0.00142705002332324\n",
      "  gamma = 0.9367370756053705\n",
      "  bsize = 15\n",
      "    * Epoch: 0\n",
      "      train loss:  0.331 [ 0.380  0.123]\n",
      "      test loss:  0.238 [ 0.371  0.105]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.235 [ 0.368  0.126]\n",
      "      test loss:  0.252 [ 0.370  0.134]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.210 [ 0.345  0.094]\n",
      "      test loss:  0.241 [ 0.367  0.115]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.195 [ 0.327  0.083]\n",
      "      test loss:  0.234 [ 0.362  0.106]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.197 [ 0.340  0.094]\n",
      "      test loss:  0.230 [ 0.350  0.110]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.194 [ 0.323  0.077]\n",
      "      test loss:  0.232 [ 0.360  0.104]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.181 [ 0.320  0.074]\n",
      "      test loss:  0.233 [ 0.362  0.105]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.178 [ 0.315  0.068]\n",
      "      test loss:  0.232 [ 0.360  0.104]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.172 [ 0.313  0.066]\n",
      "      test loss:  0.237 [ 0.361  0.114]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 06:44:16,214] Trial 52 finished with value: 0.3632480800151825 and parameters: {'lr': 0.00142705002332324, 'gamma': 0.9367370756053705, 'batch_size': 15}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.171 [ 0.311  0.063]\n",
      "      test loss:  0.240 [ 0.363  0.116]\n",
      "Final result:\n",
      "  train dice loss =  0.311480849981308\n",
      "  test dice loss =  0.3632480800151825\n",
      "Training Model...\n",
      "  lr    = 0.0016118240580633783\n",
      "  gamma = 0.8760599531153912\n",
      "  bsize = 96\n",
      "    * Epoch: 0\n",
      "      train loss:  0.697 [ 0.538  0.292]\n",
      "      test loss:  0.514 [ 0.571  0.458]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.290 [ 0.404  0.164]\n",
      "      test loss:  0.260 [ 0.377  0.142]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.249 [ 0.380  0.122]\n",
      "      test loss:  0.243 [ 0.371  0.116]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.231 [ 0.364  0.112]\n",
      "      test loss:  0.242 [ 0.368  0.116]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.221 [ 0.356  0.105]\n",
      "      test loss:  0.233 [ 0.361  0.104]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.213 [ 0.346  0.099]\n",
      "      test loss:  0.227 [ 0.349  0.105]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.211 [ 0.348  0.098]\n",
      "      test loss:  0.241 [ 0.355  0.128]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.206 [ 0.341  0.094]\n",
      "      test loss:  0.230 [ 0.352  0.109]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.202 [ 0.338  0.091]\n",
      "      test loss:  0.232 [ 0.351  0.113]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 07:03:25,327] Trial 53 finished with value: 0.35113415122032166 and parameters: {'lr': 0.0016118240580633783, 'gamma': 0.8760599531153912, 'batch_size': 96}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.200 [ 0.337  0.090]\n",
      "      test loss:  0.234 [ 0.351  0.116]\n",
      "Final result:\n",
      "  train dice loss =  0.33740168809890747\n",
      "  test dice loss =  0.35113415122032166\n",
      "Training Model...\n",
      "  lr    = 0.001768255770225329\n",
      "  gamma = 0.8859039138936817\n",
      "  bsize = 131\n",
      "    * Epoch: 0\n",
      "      train loss:  0.806 [ 0.745  0.566]\n",
      "      test loss:  0.704 [ 0.758  0.650]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.280 [ 0.431  0.297]\n",
      "      test loss:  0.280 [ 0.388  0.172]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.246 [ 0.379  0.125]\n",
      "      test loss:  0.241 [ 0.363  0.119]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.240 [ 0.372  0.113]\n",
      "      test loss:  0.243 [ 0.371  0.115]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.223 [ 0.359  0.112]\n",
      "      test loss:  0.239 [ 0.364  0.115]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.214 [ 0.350  0.101]\n",
      "      test loss:  0.231 [ 0.357  0.105]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.206 [ 0.342  0.095]\n",
      "      test loss:  0.230 [ 0.356  0.103]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.204 [ 0.349  0.094]\n",
      "      test loss:  0.255 [ 0.379  0.131]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.204 [ 0.341  0.094]\n",
      "      test loss:  0.230 [ 0.350  0.110]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 07:22:35,380] Trial 54 finished with value: 0.3567673861980438 and parameters: {'lr': 0.001768255770225329, 'gamma': 0.8859039138936817, 'batch_size': 131}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.197 [ 0.335  0.087]\n",
      "      test loss:  0.233 [ 0.357  0.110]\n",
      "Final result:\n",
      "  train dice loss =  0.33457720279693604\n",
      "  test dice loss =  0.3567673861980438\n",
      "Training Model...\n",
      "  lr    = 0.0016003886283065456\n",
      "  gamma = 0.9215143183044076\n",
      "  bsize = 164\n",
      "    * Epoch: 0\n",
      "      train loss:  0.810 [ 0.855  0.760]\n",
      "      test loss:  0.838 [ 0.844  0.831]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.289 [ 0.438  0.157]\n",
      "      test loss:  0.286 [ 0.427  0.146]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.247 [ 0.377  0.127]\n",
      "      test loss:  0.237 [ 0.365  0.110]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.230 [ 0.363  0.115]\n",
      "      test loss:  0.235 [ 0.356  0.114]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.224 [ 0.355  0.110]\n",
      "      test loss:  0.228 [ 0.351  0.105]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.213 [ 0.350  0.099]\n",
      "      test loss:  0.228 [ 0.355  0.102]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.209 [ 0.346  0.103]\n",
      "      test loss:  0.222 [ 0.339  0.105]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.205 [ 0.342  0.092]\n",
      "      test loss:  0.229 [ 0.351  0.107]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.200 [ 0.338  0.090]\n",
      "      test loss:  0.225 [ 0.342  0.108]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 07:41:41,442] Trial 55 finished with value: 0.37015965580940247 and parameters: {'lr': 0.0016003886283065456, 'gamma': 0.9215143183044076, 'batch_size': 164}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.200 [ 0.342  0.088]\n",
      "      test loss:  0.241 [ 0.370  0.113]\n",
      "Final result:\n",
      "  train dice loss =  0.34217947721481323\n",
      "  test dice loss =  0.37015965580940247\n",
      "Training Model...\n",
      "  lr    = 0.001949619399842633\n",
      "  gamma = 0.9974485217739304\n",
      "  bsize = 361\n",
      "    * Epoch: 0\n",
      "      train loss:  1.939 [ 0.643  0.721]\n",
      "      test loss:  0.677 [ 0.633  0.722]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.605 [ 0.643  0.603]\n",
      "      test loss:  0.618 [ 0.629  0.607]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.425 [ 0.689  0.502]\n",
      "      test loss:  0.675 [ 0.721  0.629]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.303 [ 0.645  0.404]\n",
      "      test loss:  0.523 [ 0.637  0.410]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.292 [ 0.412  0.164]\n",
      "      test loss:  0.271 [ 0.402  0.140]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.265 [ 0.436  0.169]\n",
      "      test loss:  0.303 [ 0.431  0.174]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.249 [ 0.391  0.132]\n",
      "      test loss:  0.252 [ 0.380  0.124]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.239 [ 0.385  0.135]\n",
      "      test loss:  0.244 [ 0.365  0.123]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.235 [ 0.388  0.138]\n",
      "      test loss:  0.268 [ 0.386  0.150]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 08:01:37,064] Trial 56 finished with value: 0.3636768162250519 and parameters: {'lr': 0.001949619399842633, 'gamma': 0.9974485217739304, 'batch_size': 361}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.231 [ 0.372  0.120]\n",
      "      test loss:  0.243 [ 0.364  0.123]\n",
      "Final result:\n",
      "  train dice loss =  0.3719686269760132\n",
      "  test dice loss =  0.3636768162250519\n",
      "Training Model...\n",
      "  lr    = 0.0013503039257591481\n",
      "  gamma = 0.2617603070157904\n",
      "  bsize = 245\n",
      "    * Epoch: 0\n",
      "      train loss:  0.761 [ 0.609  0.657]\n",
      "      test loss:  0.635 [ 0.602  0.668]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.572 [ 0.617  0.604]\n",
      "      test loss:  0.611 [ 0.607  0.615]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.531 [ 0.586  0.540]\n",
      "      test loss:  0.567 [ 0.577  0.557]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.515 [ 0.569  0.516]\n",
      "      test loss:  0.535 [ 0.554  0.517]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.510 [ 0.566  0.511]\n",
      "      test loss:  0.527 [ 0.548  0.506]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.508 [ 0.564  0.511]\n",
      "      test loss:  0.524 [ 0.546  0.502]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.507 [ 0.564  0.510]\n",
      "      test loss:  0.523 [ 0.545  0.501]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.507 [ 0.564  0.511]\n",
      "      test loss:  0.522 [ 0.545  0.500]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.507 [ 0.564  0.511]\n",
      "      test loss:  0.523 [ 0.545  0.501]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 08:20:43,003] Trial 57 finished with value: 0.5437777638435364 and parameters: {'lr': 0.0013503039257591481, 'gamma': 0.2617603070157904, 'batch_size': 245}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.508 [ 0.563  0.512]\n",
      "      test loss:  0.522 [ 0.544  0.500]\n",
      "Final result:\n",
      "  train dice loss =  0.5633044838905334\n",
      "  test dice loss =  0.5437777638435364\n",
      "Training Model...\n",
      "  lr    = 0.001018446180221767\n",
      "  gamma = 0.8665570754121086\n",
      "  bsize = 90\n",
      "    * Epoch: 0\n",
      "      train loss:  0.469 [ 0.514  0.299]\n",
      "      test loss:  0.458 [ 0.529  0.387]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.262 [ 0.386  0.130]\n",
      "      test loss:  0.244 [ 0.371  0.117]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.236 [ 0.370  0.119]\n",
      "      test loss:  0.238 [ 0.361  0.115]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.220 [ 0.353  0.107]\n",
      "      test loss:  0.233 [ 0.358  0.107]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.213 [ 0.353  0.110]\n",
      "      test loss:  0.250 [ 0.375  0.125]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.212 [ 0.347  0.099]\n",
      "      test loss:  0.238 [ 0.366  0.110]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.206 [ 0.339  0.096]\n",
      "      test loss:  0.225 [ 0.347  0.103]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.201 [ 0.336  0.093]\n",
      "      test loss:  0.232 [ 0.354  0.109]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.198 [ 0.333  0.091]\n",
      "      test loss:  0.231 [ 0.352  0.109]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 08:39:53,109] Trial 58 finished with value: 0.35013240575790405 and parameters: {'lr': 0.001018446180221767, 'gamma': 0.8665570754121086, 'batch_size': 90}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.196 [ 0.331  0.086]\n",
      "      test loss:  0.233 [ 0.350  0.116]\n",
      "Final result:\n",
      "  train dice loss =  0.33116525411605835\n",
      "  test dice loss =  0.35013240575790405\n",
      "Training Model...\n",
      "  lr    = 0.0009568018421707744\n",
      "  gamma = 0.8234065589966043\n",
      "  bsize = 88\n",
      "    * Epoch: 0\n",
      "      train loss:  0.470 [ 0.436  0.155]\n",
      "      test loss:  0.281 [ 0.420  0.143]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.257 [ 0.380  0.131]\n",
      "      test loss:  0.235 [ 0.357  0.113]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.229 [ 0.357  0.111]\n",
      "      test loss:  0.233 [ 0.356  0.110]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.221 [ 0.354  0.102]\n",
      "      test loss:  0.239 [ 0.367  0.111]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.212 [ 0.346  0.099]\n",
      "      test loss:  0.233 [ 0.356  0.109]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.205 [ 0.345  0.112]\n",
      "      test loss:  0.237 [ 0.361  0.113]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.200 [ 0.338  0.094]\n",
      "      test loss:  0.235 [ 0.359  0.112]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.196 [ 0.337  0.095]\n",
      "      test loss:  0.232 [ 0.353  0.111]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.196 [ 0.335  0.092]\n",
      "      test loss:  0.230 [ 0.351  0.110]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 08:59:34,496] Trial 59 finished with value: 0.35284096002578735 and parameters: {'lr': 0.0009568018421707744, 'gamma': 0.8234065589966043, 'batch_size': 88}. Best is trial 24 with value: 0.3477874994277954.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.194 [ 0.332  0.083]\n",
      "      test loss:  0.230 [ 0.353  0.108]\n",
      "Final result:\n",
      "  train dice loss =  0.3323301672935486\n",
      "  test dice loss =  0.35284096002578735\n",
      "Training Model...\n",
      "  lr    = 0.0009714524391675596\n",
      "  gamma = 0.8199986380677058\n",
      "  bsize = 95\n",
      "    * Epoch: 0\n",
      "      train loss:  0.494 [ 0.567  0.306]\n",
      "      test loss:  0.552 [ 0.617  0.486]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.256 [ 0.391  0.143]\n",
      "      test loss:  0.248 [ 0.370  0.125]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.231 [ 0.368  0.111]\n",
      "      test loss:  0.256 [ 0.397  0.116]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.217 [ 0.351  0.101]\n",
      "      test loss:  0.236 [ 0.357  0.116]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.208 [ 0.343  0.096]\n",
      "      test loss:  0.224 [ 0.347  0.102]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.202 [ 0.339  0.092]\n",
      "      test loss:  0.230 [ 0.352  0.108]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.199 [ 0.337  0.091]\n",
      "      test loss:  0.227 [ 0.347  0.107]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.198 [ 0.337  0.090]\n",
      "      test loss:  0.219 [ 0.336  0.102]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.195 [ 0.333  0.085]\n",
      "      test loss:  0.225 [ 0.346  0.105]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:18:44,790] Trial 60 finished with value: 0.3464803099632263 and parameters: {'lr': 0.0009714524391675596, 'gamma': 0.8199986380677058, 'batch_size': 95}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.194 [ 0.333  0.085]\n",
      "      test loss:  0.226 [ 0.346  0.105]\n",
      "Final result:\n",
      "  train dice loss =  0.3329194188117981\n",
      "  test dice loss =  0.3464803099632263\n",
      "Training Model...\n",
      "  lr    = 0.0009483317681294061\n",
      "  gamma = 0.7351310556485906\n",
      "  bsize = 92\n",
      "    * Epoch: 0\n",
      "      train loss:  0.472 [ 0.423  0.166]\n",
      "      test loss:  0.280 [ 0.405  0.155]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.254 [ 0.393  0.125]\n",
      "      test loss:  0.271 [ 0.407  0.136]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.223 [ 0.360  0.107]\n",
      "      test loss:  0.245 [ 0.372  0.118]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.214 [ 0.352  0.107]\n",
      "      test loss:  0.239 [ 0.361  0.116]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.209 [ 0.346  0.096]\n",
      "      test loss:  0.237 [ 0.361  0.113]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.205 [ 0.347  0.091]\n",
      "      test loss:  0.246 [ 0.378  0.114]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.203 [ 0.341  0.091]\n",
      "      test loss:  0.232 [ 0.360  0.103]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.201 [ 0.339  0.090]\n",
      "      test loss:  0.231 [ 0.358  0.105]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.198 [ 0.339  0.087]\n",
      "      test loss:  0.239 [ 0.368  0.111]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:37:55,263] Trial 61 finished with value: 0.36633849143981934 and parameters: {'lr': 0.0009483317681294061, 'gamma': 0.7351310556485906, 'batch_size': 92}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.197 [ 0.338  0.086]\n",
      "      test loss:  0.237 [ 0.366  0.108]\n",
      "Final result:\n",
      "  train dice loss =  0.3377481997013092\n",
      "  test dice loss =  0.36633849143981934\n",
      "Training Model...\n",
      "  lr    = 0.0007935249063158609\n",
      "  gamma = 0.8183827956082738\n",
      "  bsize = 86\n",
      "    * Epoch: 0\n",
      "      train loss:  0.443 [ 0.497  0.218]\n",
      "      test loss:  0.352 [ 0.479  0.225]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.250 [ 0.374  0.121]\n",
      "      test loss:  0.250 [ 0.383  0.118]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.225 [ 0.362  0.115]\n",
      "      test loss:  0.234 [ 0.357  0.111]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.216 [ 0.354  0.099]\n",
      "      test loss:  0.242 [ 0.367  0.118]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.209 [ 0.344  0.094]\n",
      "      test loss:  0.232 [ 0.357  0.106]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.205 [ 0.342  0.090]\n",
      "      test loss:  0.235 [ 0.366  0.104]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.201 [ 0.340  0.088]\n",
      "      test loss:  0.236 [ 0.363  0.109]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.197 [ 0.336  0.087]\n",
      "      test loss:  0.225 [ 0.349  0.102]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.196 [ 0.338  0.095]\n",
      "      test loss:  0.230 [ 0.352  0.107]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 09:57:08,191] Trial 62 finished with value: 0.35729774832725525 and parameters: {'lr': 0.0007935249063158609, 'gamma': 0.8183827956082738, 'batch_size': 86}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.194 [ 0.333  0.084]\n",
      "      test loss:  0.232 [ 0.357  0.107]\n",
      "Final result:\n",
      "  train dice loss =  0.3328424394130707\n",
      "  test dice loss =  0.35729774832725525\n",
      "Training Model...\n",
      "  lr    = 0.0008343451184934815\n",
      "  gamma = 0.7787865264329189\n",
      "  bsize = 43\n",
      "    * Epoch: 0\n",
      "      train loss:  0.363 [ 0.390  0.144]\n",
      "      test loss:  0.261 [ 0.379  0.143]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.233 [ 0.355  0.106]\n",
      "      test loss:  0.226 [ 0.354  0.098]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.216 [ 0.346  0.095]\n",
      "      test loss:  0.228 [ 0.355  0.101]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.204 [ 0.348  0.094]\n",
      "      test loss:  0.242 [ 0.368  0.116]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.197 [ 0.334  0.089]\n",
      "      test loss:  0.228 [ 0.347  0.108]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.192 [ 0.331  0.081]\n",
      "      test loss:  0.227 [ 0.344  0.110]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.189 [ 0.329  0.079]\n",
      "      test loss:  0.229 [ 0.351  0.107]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.187 [ 0.327  0.077]\n",
      "      test loss:  0.230 [ 0.349  0.112]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.185 [ 0.325  0.076]\n",
      "      test loss:  0.230 [ 0.350  0.110]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 10:16:13,403] Trial 63 finished with value: 0.35203298926353455 and parameters: {'lr': 0.0008343451184934815, 'gamma': 0.7787865264329189, 'batch_size': 43}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.184 [ 0.325  0.074]\n",
      "      test loss:  0.232 [ 0.352  0.112]\n",
      "Final result:\n",
      "  train dice loss =  0.32505002617836\n",
      "  test dice loss =  0.35203298926353455\n",
      "Training Model...\n",
      "  lr    = 0.0005785014830275002\n",
      "  gamma = 0.790986757210462\n",
      "  bsize = 36\n",
      "    * Epoch: 0\n",
      "      train loss:  0.349 [ 0.380  0.129]\n",
      "      test loss:  0.246 [ 0.369  0.123]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.227 [ 0.362  0.108]\n",
      "      test loss:  0.251 [ 0.367  0.134]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.209 [ 0.343  0.092]\n",
      "      test loss:  0.236 [ 0.357  0.116]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.202 [ 0.337  0.090]\n",
      "      test loss:  0.226 [ 0.348  0.104]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.196 [ 0.333  0.086]\n",
      "      test loss:  0.231 [ 0.351  0.112]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.191 [ 0.331  0.083]\n",
      "      test loss:  0.229 [ 0.354  0.104]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.188 [ 0.327  0.079]\n",
      "      test loss:  0.230 [ 0.351  0.108]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.185 [ 0.326  0.076]\n",
      "      test loss:  0.229 [ 0.353  0.106]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.183 [ 0.324  0.074]\n",
      "      test loss:  0.230 [ 0.354  0.106]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 10:35:21,549] Trial 64 finished with value: 0.3544268012046814 and parameters: {'lr': 0.0005785014830275002, 'gamma': 0.790986757210462, 'batch_size': 36}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.182 [ 0.323  0.073]\n",
      "      test loss:  0.231 [ 0.354  0.107]\n",
      "Final result:\n",
      "  train dice loss =  0.32269224524497986\n",
      "  test dice loss =  0.3544268012046814\n",
      "Training Model...\n",
      "  lr    = 0.0010850280436558466\n",
      "  gamma = 0.7524873435066842\n",
      "  bsize = 181\n",
      "    * Epoch: 0\n",
      "      train loss:  0.648 [ 0.933 10.018]\n",
      "      test loss: 13.872 [ 0.974 26.770]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.433 [ 0.482  0.337]\n",
      "      test loss:  0.500 [ 0.517  0.482]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.286 [ 0.421  0.154]\n",
      "      test loss:  0.274 [ 0.407  0.141]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.254 [ 0.404  0.168]\n",
      "      test loss:  0.257 [ 0.373  0.141]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.242 [ 0.382  0.131]\n",
      "      test loss:  0.243 [ 0.365  0.122]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.234 [ 0.374  0.120]\n",
      "      test loss:  0.242 [ 0.368  0.117]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.229 [ 0.367  0.116]\n",
      "      test loss:  0.237 [ 0.363  0.110]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.225 [ 0.363  0.112]\n",
      "      test loss:  0.235 [ 0.361  0.109]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.223 [ 0.361  0.110]\n",
      "      test loss:  0.234 [ 0.360  0.109]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 10:55:33,538] Trial 65 finished with value: 0.35982316732406616 and parameters: {'lr': 0.0010850280436558466, 'gamma': 0.7524873435066842, 'batch_size': 181}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.221 [ 0.359  0.108]\n",
      "      test loss:  0.234 [ 0.360  0.109]\n",
      "Final result:\n",
      "  train dice loss =  0.35909685492515564\n",
      "  test dice loss =  0.35982316732406616\n",
      "Training Model...\n",
      "  lr    = 0.00042451742257521393\n",
      "  gamma = 0.8653180657775147\n",
      "  bsize = 139\n",
      "    * Epoch: 0\n",
      "      train loss:  0.460 [ 0.486  0.236]\n",
      "      test loss:  0.339 [ 0.465  0.213]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.294 [ 0.413  0.163]\n",
      "      test loss:  0.291 [ 0.406  0.176]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.239 [ 0.369  0.122]\n",
      "      test loss:  0.244 [ 0.366  0.122]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.225 [ 0.357  0.104]\n",
      "      test loss:  0.236 [ 0.358  0.113]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.214 [ 0.350  0.099]\n",
      "      test loss:  0.231 [ 0.353  0.109]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.208 [ 0.346  0.095]\n",
      "      test loss:  0.231 [ 0.352  0.110]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.205 [ 0.343  0.092]\n",
      "      test loss:  0.232 [ 0.353  0.110]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.206 [ 0.344  0.096]\n",
      "      test loss:  0.229 [ 0.349  0.109]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.201 [ 0.340  0.089]\n",
      "      test loss:  0.229 [ 0.351  0.107]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 11:14:32,940] Trial 66 finished with value: 0.3488219082355499 and parameters: {'lr': 0.00042451742257521393, 'gamma': 0.8653180657775147, 'batch_size': 139}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.199 [ 0.340  0.091]\n",
      "      test loss:  0.228 [ 0.349  0.107]\n",
      "Final result:\n",
      "  train dice loss =  0.3395661413669586\n",
      "  test dice loss =  0.3488219082355499\n",
      "Training Model...\n",
      "  lr    = 0.0006566017426329689\n",
      "  gamma = 0.869696145962919\n",
      "  bsize = 140\n",
      "    * Epoch: 0\n",
      "      train loss:  0.499 [ 0.613  0.297]\n",
      "      test loss:  0.540 [ 0.658  0.422]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.283 [ 0.429  0.158]\n",
      "      test loss:  0.302 [ 0.430  0.175]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.236 [ 0.373  0.129]\n",
      "      test loss:  0.243 [ 0.364  0.121]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.228 [ 0.362  0.106]\n",
      "      test loss:  0.251 [ 0.377  0.126]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.215 [ 0.362  0.102]\n",
      "      test loss:  0.252 [ 0.382  0.123]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.210 [ 0.348  0.096]\n",
      "      test loss:  0.242 [ 0.363  0.122]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.206 [ 0.349  0.092]\n",
      "      test loss:  0.246 [ 0.373  0.120]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.204 [ 0.345  0.089]\n",
      "      test loss:  0.246 [ 0.371  0.121]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.200 [ 0.343  0.090]\n",
      "      test loss:  0.239 [ 0.367  0.111]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 11:36:48,813] Trial 67 finished with value: 0.36323246359825134 and parameters: {'lr': 0.0006566017426329689, 'gamma': 0.869696145962919, 'batch_size': 140}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.198 [ 0.338  0.086]\n",
      "      test loss:  0.237 [ 0.363  0.111]\n",
      "Final result:\n",
      "  train dice loss =  0.33771568536758423\n",
      "  test dice loss =  0.36323246359825134\n",
      "Training Model...\n",
      "  lr    = 0.0004018843922501427\n",
      "  gamma = 0.8563929699364037\n",
      "  bsize = 214\n",
      "    * Epoch: 0\n",
      "      train loss:  0.513 [ 0.566  0.252]\n",
      "      test loss:  0.394 [ 0.554  0.235]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.333 [ 0.480  0.208]\n",
      "      test loss:  0.344 [ 0.470  0.217]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.259 [ 0.389  0.131]\n",
      "      test loss:  0.257 [ 0.381  0.132]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.243 [ 0.383  0.138]\n",
      "      test loss:  0.244 [ 0.363  0.126]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.234 [ 0.366  0.109]\n",
      "      test loss:  0.240 [ 0.367  0.113]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.222 [ 0.362  0.105]\n",
      "      test loss:  0.243 [ 0.369  0.116]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.218 [ 0.356  0.105]\n",
      "      test loss:  0.234 [ 0.358  0.109]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.214 [ 0.355  0.099]\n",
      "      test loss:  0.238 [ 0.365  0.111]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.210 [ 0.350  0.097]\n",
      "      test loss:  0.233 [ 0.357  0.108]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 11:55:44,117] Trial 68 finished with value: 0.35942313075065613 and parameters: {'lr': 0.0004018843922501427, 'gamma': 0.8563929699364037, 'batch_size': 214}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.208 [ 0.349  0.095]\n",
      "      test loss:  0.234 [ 0.359  0.109]\n",
      "Final result:\n",
      "  train dice loss =  0.3494173288345337\n",
      "  test dice loss =  0.35942313075065613\n",
      "Training Model...\n",
      "  lr    = 0.00021443889430494055\n",
      "  gamma = 0.9094886900442836\n",
      "  bsize = 113\n",
      "    * Epoch: 0\n",
      "      train loss:  0.469 [ 0.494  0.232]\n",
      "      test loss:  0.332 [ 0.460  0.203]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.280 [ 0.391  0.132]\n",
      "      test loss:  0.255 [ 0.383  0.128]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.241 [ 0.371  0.113]\n",
      "      test loss:  0.248 [ 0.371  0.126]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.227 [ 0.363  0.104]\n",
      "      test loss:  0.246 [ 0.373  0.119]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.218 [ 0.354  0.100]\n",
      "      test loss:  0.237 [ 0.362  0.112]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.212 [ 0.348  0.098]\n",
      "      test loss:  0.239 [ 0.364  0.113]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.208 [ 0.346  0.094]\n",
      "      test loss:  0.236 [ 0.362  0.110]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.207 [ 0.346  0.096]\n",
      "      test loss:  0.237 [ 0.361  0.113]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.205 [ 0.348  0.091]\n",
      "      test loss:  0.239 [ 0.364  0.114]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 12:15:25,983] Trial 69 finished with value: 0.36118438839912415 and parameters: {'lr': 0.00021443889430494055, 'gamma': 0.9094886900442836, 'batch_size': 113}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.201 [ 0.341  0.089]\n",
      "      test loss:  0.235 [ 0.361  0.109]\n",
      "Final result:\n",
      "  train dice loss =  0.34060370922088623\n",
      "  test dice loss =  0.36118438839912415\n",
      "Training Model...\n",
      "  lr    = 0.0004682469615131902\n",
      "  gamma = 0.708560370689414\n",
      "  bsize = 136\n",
      "    * Epoch: 0\n",
      "      train loss:  0.466 [ 0.491  0.220]\n",
      "      test loss:  0.328 [ 0.469  0.188]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.277 [ 0.386  0.125]\n",
      "      test loss:  0.255 [ 0.382  0.127]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.250 [ 0.375  0.127]\n",
      "      test loss:  0.245 [ 0.366  0.125]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.228 [ 0.370  0.111]\n",
      "      test loss:  0.249 [ 0.376  0.122]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.221 [ 0.360  0.106]\n",
      "      test loss:  0.240 [ 0.361  0.119]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.216 [ 0.356  0.103]\n",
      "      test loss:  0.238 [ 0.361  0.115]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.214 [ 0.354  0.100]\n",
      "      test loss:  0.240 [ 0.361  0.118]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.212 [ 0.352  0.099]\n",
      "      test loss:  0.239 [ 0.362  0.116]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.211 [ 0.352  0.098]\n",
      "      test loss:  0.239 [ 0.362  0.116]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 12:34:26,013] Trial 70 finished with value: 0.3613705039024353 and parameters: {'lr': 0.0004682469615131902, 'gamma': 0.708560370689414, 'batch_size': 136}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.210 [ 0.351  0.097]\n",
      "      test loss:  0.239 [ 0.361  0.117]\n",
      "Final result:\n",
      "  train dice loss =  0.35103633999824524\n",
      "  test dice loss =  0.3613705039024353\n",
      "Training Model...\n",
      "  lr    = 0.0008152300611995851\n",
      "  gamma = 0.7988186975760958\n",
      "  bsize = 43\n",
      "    * Epoch: 0\n",
      "      train loss:  0.377 [ 0.399  0.169]\n",
      "      test loss:  0.256 [ 0.377  0.134]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.239 [ 0.357  0.108]\n",
      "      test loss:  0.233 [ 0.360  0.106]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.215 [ 0.345  0.097]\n",
      "      test loss:  0.232 [ 0.353  0.110]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.204 [ 0.339  0.095]\n",
      "      test loss:  0.227 [ 0.342  0.111]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.198 [ 0.334  0.088]\n",
      "      test loss:  0.239 [ 0.360  0.117]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.194 [ 0.331  0.083]\n",
      "      test loss:  0.226 [ 0.349  0.104]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.190 [ 0.328  0.081]\n",
      "      test loss:  0.233 [ 0.355  0.112]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.188 [ 0.329  0.078]\n",
      "      test loss:  0.238 [ 0.359  0.117]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.185 [ 0.325  0.077]\n",
      "      test loss:  0.233 [ 0.353  0.113]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 12:53:57,211] Trial 71 finished with value: 0.35814452171325684 and parameters: {'lr': 0.0008152300611995851, 'gamma': 0.7988186975760958, 'batch_size': 43}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.184 [ 0.326  0.075]\n",
      "      test loss:  0.236 [ 0.358  0.114]\n",
      "Final result:\n",
      "  train dice loss =  0.3261975646018982\n",
      "  test dice loss =  0.35814452171325684\n",
      "Training Model...\n",
      "  lr    = 0.0011990470434502373\n",
      "  gamma = 0.840645692542716\n",
      "  bsize = 56\n",
      "    * Epoch: 0\n",
      "      train loss:  0.492 [ 0.448  0.197]\n",
      "      test loss:  0.293 [ 0.421  0.166]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.249 [ 0.381  0.127]\n",
      "      test loss:  0.240 [ 0.362  0.117]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.226 [ 0.359  0.111]\n",
      "      test loss:  0.244 [ 0.374  0.115]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.217 [ 0.347  0.101]\n",
      "      test loss:  0.231 [ 0.355  0.108]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.205 [ 0.342  0.095]\n",
      "      test loss:  0.235 [ 0.354  0.116]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.209 [ 0.376  0.192]\n",
      "      test loss:  0.381 [ 0.396  0.367]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.208 [ 0.341  0.099]\n",
      "      test loss:  0.227 [ 0.348  0.106]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.198 [ 0.335  0.089]\n",
      "      test loss:  0.231 [ 0.353  0.110]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.194 [ 0.332  0.084]\n",
      "      test loss:  0.232 [ 0.356  0.109]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 13:13:32,591] Trial 72 finished with value: 0.3576005697250366 and parameters: {'lr': 0.0011990470434502373, 'gamma': 0.840645692542716, 'batch_size': 56}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.191 [ 0.330  0.083]\n",
      "      test loss:  0.232 [ 0.358  0.107]\n",
      "Final result:\n",
      "  train dice loss =  0.3301510512828827\n",
      "  test dice loss =  0.3576005697250366\n",
      "Training Model...\n",
      "  lr    = 0.0010530513694987725\n",
      "  gamma = 0.768930496236574\n",
      "  bsize = 150\n",
      "    * Epoch: 0\n",
      "      train loss:  0.680 [ 0.859  7.335]\n",
      "      test loss:  9.005 [ 0.938 17.071]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.308 [ 0.446  0.440]\n",
      "      test loss:  0.346 [ 0.425  0.266]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.263 [ 0.400  0.162]\n",
      "      test loss:  0.258 [ 0.377  0.138]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.242 [ 0.382  0.123]\n",
      "      test loss:  0.245 [ 0.376  0.115]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.231 [ 0.373  0.115]\n",
      "      test loss:  0.243 [ 0.373  0.114]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.226 [ 0.365  0.110]\n",
      "      test loss:  0.240 [ 0.368  0.112]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.221 [ 0.361  0.106]\n",
      "      test loss:  0.238 [ 0.367  0.110]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.218 [ 0.356  0.109]\n",
      "      test loss:  0.233 [ 0.356  0.109]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.215 [ 0.353  0.102]\n",
      "      test loss:  0.233 [ 0.359  0.107]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 13:32:28,295] Trial 73 finished with value: 0.35885247588157654 and parameters: {'lr': 0.0010530513694987725, 'gamma': 0.768930496236574, 'batch_size': 150}. Best is trial 60 with value: 0.3464803099632263.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.212 [ 0.351  0.100]\n",
      "      test loss:  0.233 [ 0.359  0.108]\n",
      "Final result:\n",
      "  train dice loss =  0.351307213306427\n",
      "  test dice loss =  0.35885247588157654\n",
      "Training Model...\n",
      "  lr    = 0.0008128276970143009\n",
      "  gamma = 0.8716629674636381\n",
      "  bsize = 9\n",
      "    * Epoch: 0\n",
      "      train loss:  0.301 [ 0.374  0.122]\n",
      "      test loss:  0.231 [ 0.357  0.105]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.222 [ 0.346  0.098]\n",
      "      test loss:  0.243 [ 0.370  0.116]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.203 [ 0.335  0.099]\n",
      "      test loss:  0.248 [ 0.381  0.115]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.192 [ 0.327  0.083]\n",
      "      test loss:  0.227 [ 0.347  0.107]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.197 [ 0.323  0.076]\n",
      "      test loss:  0.230 [ 0.354  0.107]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.182 [ 0.320  0.074]\n",
      "      test loss:  0.233 [ 0.352  0.114]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.178 [ 0.318  0.070]\n",
      "      test loss:  0.235 [ 0.352  0.118]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.175 [ 0.313  0.065]\n",
      "      test loss:  0.237 [ 0.354  0.121]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.172 [ 0.317  0.070]\n",
      "      test loss:  0.250 [ 0.365  0.135]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 13:51:01,573] Trial 74 finished with value: 0.3461824953556061 and parameters: {'lr': 0.0008128276970143009, 'gamma': 0.8716629674636381, 'batch_size': 9}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.169 [ 0.309  0.062]\n",
      "      test loss:  0.236 [ 0.346  0.126]\n",
      "Final result:\n",
      "  train dice loss =  0.3090537488460541\n",
      "  test dice loss =  0.3461824953556061\n",
      "Training Model...\n",
      "  lr    = 0.0006008353748455206\n",
      "  gamma = 0.8720939894911636\n",
      "  bsize = 554\n",
      "    * Epoch: 0\n",
      "      train loss:  0.627 [ 0.681  0.397]\n",
      "      test loss:  0.551 [ 0.690  0.412]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.499 [ 0.658  0.542]\n",
      "      test loss:  0.710 [ 0.707  0.713]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.389 [ 0.778  0.552]\n",
      "      test loss:  1.136 [ 0.822  1.449]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.325 [ 0.591  0.328]\n",
      "      test loss:  0.534 [ 0.624  0.444]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.285 [ 0.459  0.217]\n",
      "      test loss:  0.359 [ 0.455  0.263]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.265 [ 0.430  0.174]\n",
      "      test loss:  0.308 [ 0.436  0.180]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.252 [ 0.399  0.135]\n",
      "      test loss:  0.271 [ 0.411  0.131]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.246 [ 0.385  0.129]\n",
      "      test loss:  0.257 [ 0.392  0.122]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.241 [ 0.385  0.120]\n",
      "      test loss:  0.262 [ 0.401  0.122]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 14:17:05,889] Trial 75 finished with value: 0.39037713408470154 and parameters: {'lr': 0.0006008353748455206, 'gamma': 0.8720939894911636, 'batch_size': 554}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.234 [ 0.377  0.116]\n",
      "      test loss:  0.256 [ 0.390  0.121]\n",
      "Final result:\n",
      "  train dice loss =  0.3774650990962982\n",
      "  test dice loss =  0.39037713408470154\n",
      "Training Model...\n",
      "  lr    = 0.0007382827542274353\n",
      "  gamma = 0.9423694732858905\n",
      "  bsize = 11\n",
      "    * Epoch: 0\n",
      "      train loss:  0.302 [ 0.375  0.134]\n",
      "      test loss:  0.238 [ 0.360  0.116]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.221 [ 0.374  0.153]\n",
      "      test loss:  0.254 [ 0.363  0.145]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.213 [ 0.341  0.099]\n",
      "      test loss:  0.235 [ 0.356  0.115]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.197 [ 0.331  0.085]\n",
      "      test loss:  0.234 [ 0.354  0.114]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.189 [ 0.325  0.078]\n",
      "      test loss:  0.228 [ 0.351  0.106]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.181 [ 0.318  0.071]\n",
      "      test loss:  0.231 [ 0.353  0.108]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.176 [ 0.315  0.068]\n",
      "      test loss:  0.232 [ 0.360  0.104]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.174 [ 0.329  0.077]\n",
      "      test loss:  0.260 [ 0.374  0.146]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.171 [ 0.308  0.059]\n",
      "      test loss:  0.236 [ 0.355  0.117]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 14:35:34,887] Trial 76 finished with value: 0.35206618905067444 and parameters: {'lr': 0.0007382827542274353, 'gamma': 0.9423694732858905, 'batch_size': 11}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.165 [ 0.305  0.056]\n",
      "      test loss:  0.238 [ 0.352  0.125]\n",
      "Final result:\n",
      "  train dice loss =  0.30515968799591064\n",
      "  test dice loss =  0.35206618905067444\n",
      "Training Model...\n",
      "  lr    = 0.0008965046722294779\n",
      "  gamma = 0.843211473902228\n",
      "  bsize = 190\n",
      "    * Epoch: 0\n",
      "      train loss:  0.607 [ 0.713  0.563]\n",
      "      test loss:  1.119 [ 0.810  1.428]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.315 [ 0.614  0.429]\n",
      "      test loss:  0.531 [ 0.611  0.450]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.252 [ 0.387  0.123]\n",
      "      test loss:  0.259 [ 0.389  0.129]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.228 [ 0.374  0.127]\n",
      "      test loss:  0.252 [ 0.368  0.136]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.221 [ 0.357  0.105]\n",
      "      test loss:  0.241 [ 0.369  0.114]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.212 [ 0.349  0.100]\n",
      "      test loss:  0.239 [ 0.358  0.119]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.208 [ 0.347  0.095]\n",
      "      test loss:  0.243 [ 0.369  0.118]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.205 [ 0.345  0.095]\n",
      "      test loss:  0.239 [ 0.360  0.119]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.205 [ 0.345  0.092]\n",
      "      test loss:  0.242 [ 0.365  0.119]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 14:54:38,453] Trial 77 finished with value: 0.35922423005104065 and parameters: {'lr': 0.0008965046722294779, 'gamma': 0.843211473902228, 'batch_size': 190}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.202 [ 0.341  0.091]\n",
      "      test loss:  0.238 [ 0.359  0.118]\n",
      "Final result:\n",
      "  train dice loss =  0.3412097990512848\n",
      "  test dice loss =  0.35922423005104065\n",
      "Training Model...\n",
      "  lr    = 0.0011002526033612574\n",
      "  gamma = 0.9086922925853333\n",
      "  bsize = 108\n",
      "    * Epoch: 0\n",
      "      train loss:  0.555 [ 0.749  1.041]\n",
      "      test loss:  2.164 [ 0.848  3.481]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.288 [ 0.443  0.229]\n",
      "      test loss:  0.302 [ 0.408  0.195]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.243 [ 0.415  0.156]\n",
      "      test loss:  0.312 [ 0.435  0.188]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.229 [ 0.366  0.114]\n",
      "      test loss:  0.257 [ 0.390  0.124]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.227 [ 0.368  0.139]\n",
      "      test loss:  0.260 [ 0.378  0.142]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.220 [ 0.352  0.112]\n",
      "      test loss:  0.239 [ 0.365  0.113]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.209 [ 0.346  0.098]\n",
      "      test loss:  0.252 [ 0.387  0.116]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.205 [ 0.341  0.097]\n",
      "      test loss:  0.235 [ 0.364  0.106]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.202 [ 0.339  0.093]\n",
      "      test loss:  0.241 [ 0.368  0.113]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 15:13:42,277] Trial 78 finished with value: 0.3526424765586853 and parameters: {'lr': 0.0011002526033612574, 'gamma': 0.9086922925853333, 'batch_size': 108}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.200 [ 0.336  0.090]\n",
      "      test loss:  0.229 [ 0.353  0.105]\n",
      "Final result:\n",
      "  train dice loss =  0.3358650803565979\n",
      "  test dice loss =  0.3526424765586853\n",
      "Training Model...\n",
      "  lr    = 0.00041976001831386755\n",
      "  gamma = 0.8809321489256092\n",
      "  bsize = 722\n",
      "    * Epoch: 0\n",
      "      train loss:  0.607 [ 0.748  0.499]\n",
      "      test loss:  0.706 [ 0.780  0.633]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.474 [ 0.617  0.310]\n",
      "      test loss:  0.486 [ 0.625  0.347]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.402 [ 0.788  0.562]\n",
      "      test loss:  0.760 [ 0.798  0.722]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.435 [ 0.544  0.312]\n",
      "      test loss:  0.386 [ 0.502  0.270]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.395 [ 0.528  0.237]\n",
      "      test loss:  0.369 [ 0.507  0.232]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.355 [ 0.545  0.215]\n",
      "      test loss:  0.382 [ 0.535  0.229]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.333 [ 0.475  0.196]\n",
      "      test loss:  0.318 [ 0.456  0.181]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.318 [ 0.464  0.190]\n",
      "      test loss:  0.309 [ 0.446  0.172]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.299 [ 0.447  0.166]\n",
      "      test loss:  0.298 [ 0.435  0.160]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 15:32:47,723] Trial 79 finished with value: 0.41091465950012207 and parameters: {'lr': 0.00041976001831386755, 'gamma': 0.8809321489256092, 'batch_size': 722}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.283 [ 0.423  0.155]\n",
      "      test loss:  0.280 [ 0.411  0.149]\n",
      "Final result:\n",
      "  train dice loss =  0.42333871126174927\n",
      "  test dice loss =  0.41091465950012207\n",
      "Training Model...\n",
      "  lr    = 2.8571909223674887e-05\n",
      "  gamma = 0.9554501786265192\n",
      "  bsize = 323\n",
      "    * Epoch: 0\n",
      "      train loss:  0.660 [ 0.655  0.685]\n",
      "      test loss:  0.663 [ 0.644  0.683]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.619 [ 0.658  0.437]\n",
      "      test loss:  0.544 [ 0.655  0.433]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.517 [ 0.669  0.353]\n",
      "      test loss:  0.538 [ 0.689  0.386]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.474 [ 0.617  0.319]\n",
      "      test loss:  0.477 [ 0.625  0.330]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.451 [ 0.569  0.301]\n",
      "      test loss:  0.429 [ 0.564  0.293]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.419 [ 0.539  0.294]\n",
      "      test loss:  0.395 [ 0.520  0.271]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.392 [ 0.528  0.289]\n",
      "      test loss:  0.379 [ 0.499  0.258]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.373 [ 0.510  0.235]\n",
      "      test loss:  0.358 [ 0.498  0.218]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.362 [ 0.500  0.219]\n",
      "      test loss:  0.350 [ 0.493  0.207]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 15:51:50,120] Trial 80 finished with value: 0.4836687743663788 and parameters: {'lr': 2.8571909223674887e-05, 'gamma': 0.9554501786265192, 'batch_size': 323}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.348 [ 0.490  0.207]\n",
      "      test loss:  0.340 [ 0.484  0.196]\n",
      "Final result:\n",
      "  train dice loss =  0.4900146424770355\n",
      "  test dice loss =  0.4836687743663788\n",
      "Training Model...\n",
      "  lr    = 0.0008065282852204545\n",
      "  gamma = 0.5977446726646988\n",
      "  bsize = 7\n",
      "    * Epoch: 0\n",
      "      train loss:  0.308 [ 0.471  0.257]\n",
      "      test loss:  0.352 [ 0.438  0.267]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.234 [ 0.369  0.120]\n",
      "      test loss:  0.246 [ 0.374  0.118]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.212 [ 0.339  0.097]\n",
      "      test loss:  0.232 [ 0.356  0.108]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.200 [ 0.333  0.090]\n",
      "      test loss:  0.225 [ 0.351  0.100]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.194 [ 0.329  0.085]\n",
      "      test loss:  0.227 [ 0.353  0.101]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.191 [ 0.327  0.082]\n",
      "      test loss:  0.225 [ 0.349  0.100]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.188 [ 0.326  0.080]\n",
      "      test loss:  0.224 [ 0.350  0.098]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.186 [ 0.324  0.079]\n",
      "      test loss:  0.222 [ 0.348  0.096]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.186 [ 0.323  0.079]\n",
      "      test loss:  0.222 [ 0.346  0.099]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 16:10:45,174] Trial 81 finished with value: 0.34713417291641235 and parameters: {'lr': 0.0008065282852204545, 'gamma': 0.5977446726646988, 'batch_size': 7}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.184 [ 0.323  0.078]\n",
      "      test loss:  0.223 [ 0.347  0.098]\n",
      "Final result:\n",
      "  train dice loss =  0.32291555404663086\n",
      "  test dice loss =  0.34713417291641235\n",
      "Training Model...\n",
      "  lr    = 0.0002975235885377443\n",
      "  gamma = 0.6115395418113411\n",
      "  bsize = 78\n",
      "    * Epoch: 0\n",
      "      train loss:  0.407 [ 0.428  0.157]\n",
      "      test loss:  0.281 [ 0.415  0.147]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.252 [ 0.380  0.120]\n",
      "      test loss:  0.251 [ 0.376  0.127]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.231 [ 0.363  0.110]\n",
      "      test loss:  0.243 [ 0.366  0.120]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.220 [ 0.357  0.104]\n",
      "      test loss:  0.241 [ 0.364  0.117]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.215 [ 0.356  0.100]\n",
      "      test loss:  0.241 [ 0.361  0.120]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.213 [ 0.352  0.100]\n",
      "      test loss:  0.240 [ 0.361  0.118]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.212 [ 0.354  0.099]\n",
      "      test loss:  0.242 [ 0.365  0.119]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.210 [ 0.351  0.098]\n",
      "      test loss:  0.240 [ 0.362  0.118]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.210 [ 0.351  0.098]\n",
      "      test loss:  0.238 [ 0.359  0.117]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 16:29:50,159] Trial 82 finished with value: 0.36081165075302124 and parameters: {'lr': 0.0002975235885377443, 'gamma': 0.6115395418113411, 'batch_size': 78}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.209 [ 0.351  0.098]\n",
      "      test loss:  0.239 [ 0.361  0.117]\n",
      "Final result:\n",
      "  train dice loss =  0.35067251324653625\n",
      "  test dice loss =  0.36081165075302124\n",
      "Training Model...\n",
      "  lr    = 0.0007686820326783245\n",
      "  gamma = 0.6057337385111814\n",
      "  bsize = 12\n",
      "    * Epoch: 0\n",
      "      train loss:  0.309 [ 0.372  0.137]\n",
      "      test loss:  0.273 [ 0.374  0.173]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.226 [ 0.346  0.103]\n",
      "      test loss:  0.237 [ 0.359  0.115]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.204 [ 0.336  0.093]\n",
      "      test loss:  0.233 [ 0.356  0.111]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.199 [ 0.337  0.101]\n",
      "      test loss:  0.230 [ 0.353  0.107]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.193 [ 0.329  0.083]\n",
      "      test loss:  0.227 [ 0.356  0.099]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.189 [ 0.327  0.083]\n",
      "      test loss:  0.227 [ 0.352  0.101]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.187 [ 0.326  0.081]\n",
      "      test loss:  0.228 [ 0.355  0.102]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.186 [ 0.325  0.079]\n",
      "      test loss:  0.229 [ 0.355  0.103]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.186 [ 0.325  0.078]\n",
      "      test loss:  0.230 [ 0.356  0.104]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 16:47:45,355] Trial 83 finished with value: 0.3541543185710907 and parameters: {'lr': 0.0007686820326783245, 'gamma': 0.6057337385111814, 'batch_size': 12}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.186 [ 0.324  0.078]\n",
      "      test loss:  0.228 [ 0.354  0.102]\n",
      "Final result:\n",
      "  train dice loss =  0.32437944412231445\n",
      "  test dice loss =  0.3541543185710907\n",
      "Training Model...\n",
      "  lr    = 0.0006712170665541638\n",
      "  gamma = 0.5754975753886238\n",
      "  bsize = 5\n",
      "    * Epoch: 0\n",
      "      train loss:  0.310 [ 0.390  0.163]\n",
      "      test loss:  0.254 [ 0.368  0.140]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.225 [ 0.347  0.104]\n",
      "      test loss:  0.229 [ 0.349  0.108]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.207 [ 0.334  0.090]\n",
      "      test loss:  0.220 [ 0.346  0.094]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.195 [ 0.330  0.082]\n",
      "      test loss:  0.229 [ 0.357  0.101]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.189 [ 0.326  0.079]\n",
      "      test loss:  0.229 [ 0.354  0.103]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.186 [ 0.324  0.078]\n",
      "      test loss:  0.226 [ 0.351  0.101]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.184 [ 0.322  0.076]\n",
      "      test loss:  0.223 [ 0.344  0.102]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.182 [ 0.322  0.075]\n",
      "      test loss:  0.225 [ 0.350  0.101]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.182 [ 0.321  0.075]\n",
      "      test loss:  0.225 [ 0.348  0.102]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 17:06:46,109] Trial 84 finished with value: 0.34816309809684753 and parameters: {'lr': 0.0006712170665541638, 'gamma': 0.5754975753886238, 'batch_size': 5}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.181 [ 0.321  0.074]\n",
      "      test loss:  0.225 [ 0.348  0.101]\n",
      "Final result:\n",
      "  train dice loss =  0.32095450162887573\n",
      "  test dice loss =  0.34816309809684753\n",
      "Training Model...\n",
      "  lr    = 0.0008622106638868828\n",
      "  gamma = 0.49616103551916046\n",
      "  bsize = 53\n",
      "    * Epoch: 0\n",
      "      train loss:  0.400 [ 0.411  0.180]\n",
      "      test loss:  0.266 [ 0.381  0.151]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.242 [ 0.368  0.116]\n",
      "      test loss:  0.240 [ 0.370  0.110]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.223 [ 0.359  0.113]\n",
      "      test loss:  0.233 [ 0.354  0.112]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.217 [ 0.353  0.101]\n",
      "      test loss:  0.235 [ 0.359  0.112]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.211 [ 0.349  0.099]\n",
      "      test loss:  0.233 [ 0.356  0.111]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.208 [ 0.348  0.097]\n",
      "      test loss:  0.235 [ 0.357  0.112]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.208 [ 0.347  0.096]\n",
      "      test loss:  0.235 [ 0.358  0.112]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.207 [ 0.347  0.096]\n",
      "      test loss:  0.234 [ 0.356  0.112]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.207 [ 0.347  0.096]\n",
      "      test loss:  0.235 [ 0.358  0.112]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 17:25:43,450] Trial 85 finished with value: 0.35729146003723145 and parameters: {'lr': 0.0008622106638868828, 'gamma': 0.49616103551916046, 'batch_size': 53}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.206 [ 0.347  0.096]\n",
      "      test loss:  0.235 [ 0.357  0.112]\n",
      "Final result:\n",
      "  train dice loss =  0.3467455208301544\n",
      "  test dice loss =  0.35729146003723145\n",
      "Training Model...\n",
      "  lr    = 0.0006695237362467027\n",
      "  gamma = 0.533798014478168\n",
      "  bsize = 32\n",
      "    * Epoch: 0\n",
      "      train loss:  0.341 [ 0.380  0.131]\n",
      "      test loss:  0.252 [ 0.370  0.135]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.227 [ 0.354  0.100]\n",
      "      test loss:  0.240 [ 0.361  0.119]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.209 [ 0.345  0.094]\n",
      "      test loss:  0.239 [ 0.359  0.119]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.203 [ 0.342  0.089]\n",
      "      test loss:  0.240 [ 0.364  0.115]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.199 [ 0.337  0.088]\n",
      "      test loss:  0.235 [ 0.356  0.114]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.197 [ 0.336  0.087]\n",
      "      test loss:  0.235 [ 0.358  0.113]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.196 [ 0.336  0.086]\n",
      "      test loss:  0.235 [ 0.355  0.114]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.196 [ 0.336  0.085]\n",
      "      test loss:  0.236 [ 0.358  0.113]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.195 [ 0.335  0.086]\n",
      "      test loss:  0.235 [ 0.357  0.114]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 17:44:35,213] Trial 86 finished with value: 0.35526520013809204 and parameters: {'lr': 0.0006695237362467027, 'gamma': 0.533798014478168, 'batch_size': 32}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.195 [ 0.335  0.086]\n",
      "      test loss:  0.234 [ 0.355  0.114]\n",
      "Final result:\n",
      "  train dice loss =  0.3352373540401459\n",
      "  test dice loss =  0.35526520013809204\n",
      "Training Model...\n",
      "  lr    = 0.0010067571385655961\n",
      "  gamma = 0.5845460994038061\n",
      "  bsize = 125\n",
      "    * Epoch: 0\n",
      "      train loss:  0.547 [ 0.629  0.384]\n",
      "      test loss:  0.597 [ 0.669  0.524]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.274 [ 0.427  0.193]\n",
      "      test loss:  0.277 [ 0.392  0.163]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.241 [ 0.370  0.118]\n",
      "      test loss:  0.240 [ 0.366  0.115]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.226 [ 0.363  0.112]\n",
      "      test loss:  0.238 [ 0.363  0.112]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.221 [ 0.359  0.108]\n",
      "      test loss:  0.236 [ 0.359  0.112]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.218 [ 0.358  0.106]\n",
      "      test loss:  0.235 [ 0.359  0.112]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.217 [ 0.355  0.106]\n",
      "      test loss:  0.234 [ 0.356  0.112]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.216 [ 0.355  0.104]\n",
      "      test loss:  0.234 [ 0.356  0.112]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.214 [ 0.354  0.104]\n",
      "      test loss:  0.233 [ 0.355  0.111]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 18:03:25,248] Trial 87 finished with value: 0.3556491732597351 and parameters: {'lr': 0.0010067571385655961, 'gamma': 0.5845460994038061, 'batch_size': 125}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.214 [ 0.354  0.104]\n",
      "      test loss:  0.234 [ 0.356  0.112]\n",
      "Final result:\n",
      "  train dice loss =  0.35397469997406006\n",
      "  test dice loss =  0.3556491732597351\n",
      "Training Model...\n",
      "  lr    = 0.0005148271884481625\n",
      "  gamma = 0.5145150448955972\n",
      "  bsize = 228\n",
      "    * Epoch: 0\n",
      "      train loss:  0.529 [ 0.713  0.536]\n",
      "      test loss:  0.728 [ 0.762  0.694]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.365 [ 0.479  0.191]\n",
      "      test loss:  0.330 [ 0.467  0.192]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.282 [ 0.423  0.152]\n",
      "      test loss:  0.275 [ 0.410  0.140]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.256 [ 0.402  0.133]\n",
      "      test loss:  0.259 [ 0.390  0.129]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.248 [ 0.393  0.127]\n",
      "      test loss:  0.254 [ 0.384  0.125]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.245 [ 0.387  0.127]\n",
      "      test loss:  0.250 [ 0.378  0.122]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.243 [ 0.386  0.125]\n",
      "      test loss:  0.250 [ 0.378  0.122]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.242 [ 0.386  0.124]\n",
      "      test loss:  0.250 [ 0.378  0.122]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.242 [ 0.385  0.125]\n",
      "      test loss:  0.249 [ 0.377  0.122]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 18:22:24,046] Trial 88 finished with value: 0.37736624479293823 and parameters: {'lr': 0.0005148271884481625, 'gamma': 0.5145150448955972, 'batch_size': 228}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.241 [ 0.385  0.124]\n",
      "      test loss:  0.250 [ 0.377  0.122]\n",
      "Final result:\n",
      "  train dice loss =  0.3853713274002075\n",
      "  test dice loss =  0.37736624479293823\n",
      "Training Model...\n",
      "  lr    = 0.000706249836445257\n",
      "  gamma = 0.6527077492662468\n",
      "  bsize = 6\n",
      "    * Epoch: 0\n",
      "      train loss:  0.318 [ 0.370  0.118]\n",
      "      test loss:  0.228 [ 0.354  0.102]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.224 [ 0.345  0.098]\n",
      "      test loss:  0.233 [ 0.360  0.106]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.210 [ 0.346  0.108]\n",
      "      test loss:  0.230 [ 0.347  0.113]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.196 [ 0.330  0.081]\n",
      "      test loss:  0.229 [ 0.359  0.099]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.189 [ 0.324  0.077]\n",
      "      test loss:  0.230 [ 0.360  0.100]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.185 [ 0.323  0.075]\n",
      "      test loss:  0.232 [ 0.359  0.104]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.182 [ 0.323  0.076]\n",
      "      test loss:  0.226 [ 0.348  0.105]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.181 [ 0.320  0.072]\n",
      "      test loss:  0.226 [ 0.345  0.106]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.179 [ 0.319  0.071]\n",
      "      test loss:  0.231 [ 0.357  0.106]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 18:41:55,635] Trial 89 finished with value: 0.35541844367980957 and parameters: {'lr': 0.000706249836445257, 'gamma': 0.6527077492662468, 'batch_size': 6}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.178 [ 0.319  0.071]\n",
      "      test loss:  0.231 [ 0.355  0.107]\n",
      "Final result:\n",
      "  train dice loss =  0.3186021149158478\n",
      "  test dice loss =  0.35541844367980957\n",
      "Training Model...\n",
      "  lr    = 0.0006060548570339097\n",
      "  gamma = 0.4365173725778918\n",
      "  bsize = 453\n",
      "    * Epoch: 0\n",
      "      train loss:  0.637 [ 0.776  0.712]\n",
      "      test loss:  0.841 [ 0.805  0.878]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.467 [ 0.615  0.324]\n",
      "      test loss:  0.595 [ 0.661  0.529]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.410 [ 0.564  0.269]\n",
      "      test loss:  0.444 [ 0.572  0.316]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.368 [ 0.504  0.238]\n",
      "      test loss:  0.351 [ 0.484  0.218]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.349 [ 0.491  0.220]\n",
      "      test loss:  0.336 [ 0.474  0.197]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.340 [ 0.483  0.214]\n",
      "      test loss:  0.328 [ 0.468  0.188]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.336 [ 0.481  0.210]\n",
      "      test loss:  0.326 [ 0.466  0.185]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.334 [ 0.478  0.210]\n",
      "      test loss:  0.323 [ 0.463  0.183]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.334 [ 0.477  0.210]\n",
      "      test loss:  0.322 [ 0.462  0.183]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 19:00:53,002] Trial 90 finished with value: 0.46244359016418457 and parameters: {'lr': 0.0006060548570339097, 'gamma': 0.4365173725778918, 'batch_size': 453}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.333 [ 0.477  0.208]\n",
      "      test loss:  0.322 [ 0.462  0.182]\n",
      "Final result:\n",
      "  train dice loss =  0.4774450659751892\n",
      "  test dice loss =  0.46244359016418457\n",
      "Training Model...\n",
      "  lr    = 0.0023307010736677352\n",
      "  gamma = 0.6431449124155565\n",
      "  bsize = 104\n",
      "    * Epoch: 0\n",
      "      train loss:  1.208 [ 0.479  0.238]\n",
      "      test loss:  0.379 [ 0.460  0.298]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.279 [ 0.409  0.161]\n",
      "      test loss:  0.264 [ 0.383  0.145]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.248 [ 0.382  0.124]\n",
      "      test loss:  0.251 [ 0.375  0.126]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.241 [ 0.382  0.122]\n",
      "      test loss:  0.256 [ 0.380  0.131]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.230 [ 0.370  0.120]\n",
      "      test loss:  0.242 [ 0.364  0.119]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.228 [ 0.369  0.113]\n",
      "      test loss:  0.249 [ 0.373  0.124]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.225 [ 0.365  0.112]\n",
      "      test loss:  0.243 [ 0.367  0.119]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.223 [ 0.364  0.112]\n",
      "      test loss:  0.243 [ 0.366  0.120]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.221 [ 0.363  0.110]\n",
      "      test loss:  0.244 [ 0.367  0.121]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 19:19:57,527] Trial 91 finished with value: 0.36741986870765686 and parameters: {'lr': 0.0023307010736677352, 'gamma': 0.6431449124155565, 'batch_size': 104}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.221 [ 0.362  0.110]\n",
      "      test loss:  0.244 [ 0.367  0.121]\n",
      "Final result:\n",
      "  train dice loss =  0.36208146810531616\n",
      "  test dice loss =  0.36741986870765686\n",
      "Training Model...\n",
      "  lr    = 0.0009455777367827396\n",
      "  gamma = 0.5576110964328219\n",
      "  bsize = 67\n",
      "    * Epoch: 0\n",
      "      train loss:  0.432 [ 0.423  0.194]\n",
      "      test loss:  0.279 [ 0.391  0.167]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.252 [ 0.386  0.131]\n",
      "      test loss:  0.250 [ 0.374  0.126]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.233 [ 0.362  0.115]\n",
      "      test loss:  0.239 [ 0.358  0.119]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.219 [ 0.353  0.105]\n",
      "      test loss:  0.230 [ 0.351  0.109]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.214 [ 0.349  0.101]\n",
      "      test loss:  0.229 [ 0.353  0.106]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.211 [ 0.349  0.099]\n",
      "      test loss:  0.234 [ 0.354  0.113]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.210 [ 0.347  0.098]\n",
      "      test loss:  0.234 [ 0.354  0.114]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.208 [ 0.346  0.097]\n",
      "      test loss:  0.235 [ 0.354  0.116]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.208 [ 0.346  0.099]\n",
      "      test loss:  0.232 [ 0.353  0.112]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 19:39:01,073] Trial 92 finished with value: 0.35508060455322266 and parameters: {'lr': 0.0009455777367827396, 'gamma': 0.5576110964328219, 'batch_size': 67}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.209 [ 0.347  0.097]\n",
      "      test loss:  0.237 [ 0.355  0.120]\n",
      "Final result:\n",
      "  train dice loss =  0.34676557779312134\n",
      "  test dice loss =  0.35508060455322266\n",
      "Training Model...\n",
      "  lr    = 0.001035912307214087\n",
      "  gamma = 0.5835494884049823\n",
      "  bsize = 268\n",
      "    * Epoch: 0\n",
      "      train loss:  0.670 [ 0.615  0.628]\n",
      "      test loss:  0.626 [ 0.609  0.643]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.514 [ 0.599  0.366]\n",
      "      test loss:  0.513 [ 0.603  0.423]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.321 [ 0.438  0.170]\n",
      "      test loss:  0.300 [ 0.429  0.170]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.278 [ 0.414  0.148]\n",
      "      test loss:  0.268 [ 0.400  0.136]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.260 [ 0.400  0.145]\n",
      "      test loss:  0.257 [ 0.385  0.129]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.252 [ 0.396  0.137]\n",
      "      test loss:  0.255 [ 0.383  0.126]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.248 [ 0.394  0.130]\n",
      "      test loss:  0.256 [ 0.386  0.126]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.245 [ 0.391  0.130]\n",
      "      test loss:  0.252 [ 0.381  0.123]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.244 [ 0.390  0.129]\n",
      "      test loss:  0.252 [ 0.381  0.123]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 19:58:04,489] Trial 93 finished with value: 0.3820957541465759 and parameters: {'lr': 0.001035912307214087, 'gamma': 0.5835494884049823, 'batch_size': 268}. Best is trial 74 with value: 0.3461824953556061.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.243 [ 0.390  0.127]\n",
      "      test loss:  0.253 [ 0.382  0.123]\n",
      "Final result:\n",
      "  train dice loss =  0.3900279104709625\n",
      "  test dice loss =  0.3820957541465759\n",
      "Training Model...\n",
      "  lr    = 0.0009046296112615856\n",
      "  gamma = 0.9678318664434684\n",
      "  bsize = 174\n",
      "    * Epoch: 0\n",
      "      train loss:  0.607 [ 0.634  0.421]\n",
      "      test loss:  0.547 [ 0.635  0.458]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.311 [ 0.426  0.152]\n",
      "      test loss:  0.282 [ 0.415  0.149]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.248 [ 0.378  0.137]\n",
      "      test loss:  0.247 [ 0.366  0.128]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.237 [ 0.366  0.123]\n",
      "      test loss:  0.238 [ 0.356  0.120]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.221 [ 0.355  0.106]\n",
      "      test loss:  0.233 [ 0.352  0.113]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.211 [ 0.353  0.102]\n",
      "      test loss:  0.254 [ 0.390  0.119]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.206 [ 0.346  0.101]\n",
      "      test loss:  0.232 [ 0.349  0.115]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.203 [ 0.340  0.095]\n",
      "      test loss:  0.231 [ 0.354  0.107]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.202 [ 0.338  0.089]\n",
      "      test loss:  0.230 [ 0.354  0.106]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 20:20:15,267] Trial 94 finished with value: 0.3421245813369751 and parameters: {'lr': 0.0009046296112615856, 'gamma': 0.9678318664434684, 'batch_size': 174}. Best is trial 94 with value: 0.3421245813369751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.197 [ 0.335  0.087]\n",
      "      test loss:  0.227 [ 0.342  0.112]\n",
      "Final result:\n",
      "  train dice loss =  0.3345676064491272\n",
      "  test dice loss =  0.3421245813369751\n",
      "Training Model...\n",
      "  lr    = 0.0007606427625534983\n",
      "  gamma = 0.9792050599158075\n",
      "  bsize = 204\n",
      "    * Epoch: 0\n",
      "      train loss:  0.532 [ 0.577  0.327]\n",
      "      test loss:  0.516 [ 0.594  0.438]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.314 [ 0.476  0.231]\n",
      "      test loss:  0.424 [ 0.514  0.335]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.246 [ 0.384  0.122]\n",
      "      test loss:  0.264 [ 0.400  0.128]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.232 [ 0.386  0.121]\n",
      "      test loss:  0.271 [ 0.403  0.139]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.234 [ 0.371  0.117]\n",
      "      test loss:  0.262 [ 0.385  0.140]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.222 [ 0.359  0.110]\n",
      "      test loss:  0.247 [ 0.365  0.130]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.209 [ 0.349  0.093]\n",
      "      test loss:  0.243 [ 0.369  0.117]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.204 [ 0.342  0.093]\n",
      "      test loss:  0.236 [ 0.357  0.115]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.203 [ 0.347  0.097]\n",
      "      test loss:  0.235 [ 0.355  0.115]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 20:42:51,577] Trial 95 finished with value: 0.3538316488265991 and parameters: {'lr': 0.0007606427625534983, 'gamma': 0.9792050599158075, 'batch_size': 204}. Best is trial 94 with value: 0.3421245813369751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.200 [ 0.342  0.096]\n",
      "      test loss:  0.240 [ 0.354  0.125]\n",
      "Final result:\n",
      "  train dice loss =  0.34168732166290283\n",
      "  test dice loss =  0.3538316488265991\n",
      "Training Model...\n",
      "  lr    = 0.001180016158527563\n",
      "  gamma = 0.6786295861248157\n",
      "  bsize = 153\n",
      "    * Epoch: 0\n",
      "      train loss:  0.669 [ 0.634  0.644]\n",
      "      test loss:  0.617 [ 0.612  0.622]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.475 [ 0.460  0.198]\n",
      "      test loss:  0.308 [ 0.431  0.186]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.283 [ 0.407  0.155]\n",
      "      test loss:  0.263 [ 0.391  0.136]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.257 [ 0.391  0.133]\n",
      "      test loss:  0.255 [ 0.378  0.133]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.242 [ 0.384  0.128]\n",
      "      test loss:  0.246 [ 0.370  0.122]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.236 [ 0.380  0.129]\n",
      "      test loss:  0.244 [ 0.368  0.120]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.231 [ 0.371  0.116]\n",
      "      test loss:  0.243 [ 0.368  0.118]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.227 [ 0.370  0.112]\n",
      "      test loss:  0.243 [ 0.372  0.113]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.225 [ 0.367  0.110]\n",
      "      test loss:  0.242 [ 0.367  0.116]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 21:01:50,453] Trial 96 finished with value: 0.367504358291626 and parameters: {'lr': 0.001180016158527563, 'gamma': 0.6786295861248157, 'batch_size': 153}. Best is trial 94 with value: 0.3421245813369751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.223 [ 0.366  0.109]\n",
      "      test loss:  0.241 [ 0.368  0.114]\n",
      "Final result:\n",
      "  train dice loss =  0.3657761812210083\n",
      "  test dice loss =  0.367504358291626\n",
      "Training Model...\n",
      "  lr    = 0.0008767689799292743\n",
      "  gamma = 0.9692198792969511\n",
      "  bsize = 258\n",
      "    * Epoch: 0\n",
      "      train loss:  0.667 [ 0.640  0.590]\n",
      "      test loss:  0.602 [ 0.623  0.581]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.412 [ 0.785  1.001]\n",
      "      test loss:  0.953 [ 0.761  1.145]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.270 [ 0.471  0.235]\n",
      "      test loss:  0.451 [ 0.479  0.424]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.246 [ 0.381  0.125]\n",
      "      test loss:  0.247 [ 0.372  0.121]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.230 [ 0.368  0.117]\n",
      "      test loss:  0.235 [ 0.357  0.113]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.217 [ 0.357  0.108]\n",
      "      test loss:  0.234 [ 0.359  0.109]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.214 [ 0.352  0.105]\n",
      "      test loss:  0.241 [ 0.357  0.125]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.211 [ 0.349  0.103]\n",
      "      test loss:  0.231 [ 0.349  0.112]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.205 [ 0.344  0.093]\n",
      "      test loss:  0.228 [ 0.349  0.107]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 21:20:52,825] Trial 97 finished with value: 0.3618219494819641 and parameters: {'lr': 0.0008767689799292743, 'gamma': 0.9692198792969511, 'batch_size': 258}. Best is trial 94 with value: 0.3421245813369751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.207 [ 0.345  0.090]\n",
      "      test loss:  0.234 [ 0.362  0.106]\n",
      "Final result:\n",
      "  train dice loss =  0.3449491858482361\n",
      "  test dice loss =  0.3618219494819641\n",
      "Training Model...\n",
      "  lr    = 0.0009890150172657405\n",
      "  gamma = 0.9317410330542315\n",
      "  bsize = 35\n",
      "    * Epoch: 0\n",
      "      train loss:  0.358 [ 0.411  0.144]\n",
      "      test loss:  0.266 [ 0.408  0.124]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.241 [ 0.363  0.115]\n",
      "      test loss:  0.238 [ 0.361  0.115]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.221 [ 0.348  0.101]\n",
      "      test loss:  0.227 [ 0.355  0.098]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.212 [ 0.340  0.092]\n",
      "      test loss:  0.235 [ 0.360  0.110]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.197 [ 0.335  0.083]\n",
      "      test loss:  0.240 [ 0.365  0.115]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.191 [ 0.327  0.078]\n",
      "      test loss:  0.231 [ 0.353  0.109]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.187 [ 0.325  0.080]\n",
      "      test loss:  0.232 [ 0.348  0.115]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.181 [ 0.324  0.075]\n",
      "      test loss:  0.238 [ 0.355  0.122]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.178 [ 0.318  0.071]\n",
      "      test loss:  0.233 [ 0.349  0.118]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 21:39:54,410] Trial 98 finished with value: 0.35277697443962097 and parameters: {'lr': 0.0009890150172657405, 'gamma': 0.9317410330542315, 'batch_size': 35}. Best is trial 94 with value: 0.3421245813369751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.175 [ 0.315  0.067]\n",
      "      test loss:  0.237 [ 0.353  0.122]\n",
      "Final result:\n",
      "  train dice loss =  0.31471964716911316\n",
      "  test dice loss =  0.35277697443962097\n",
      "Training Model...\n",
      "  lr    = 0.001220524032668122\n",
      "  gamma = 0.9539199670725702\n",
      "  bsize = 173\n",
      "    * Epoch: 0\n",
      "      train loss:  0.671 [ 0.661  2.938]\n",
      "      test loss:  1.615 [ 0.633  2.596]\n",
      "    * Epoch: 1\n",
      "      train loss:  0.342 [ 0.499  0.219]\n",
      "      test loss:  0.372 [ 0.499  0.244]\n",
      "    * Epoch: 2\n",
      "      train loss:  0.266 [ 0.399  0.143]\n",
      "      test loss:  0.255 [ 0.381  0.130]\n",
      "    * Epoch: 3\n",
      "      train loss:  0.241 [ 0.376  0.123]\n",
      "      test loss:  0.245 [ 0.370  0.121]\n",
      "    * Epoch: 4\n",
      "      train loss:  0.232 [ 0.378  0.117]\n",
      "      test loss:  0.259 [ 0.394  0.124]\n",
      "    * Epoch: 5\n",
      "      train loss:  0.222 [ 0.357  0.106]\n",
      "      test loss:  0.246 [ 0.370  0.121]\n",
      "    * Epoch: 6\n",
      "      train loss:  0.213 [ 0.349  0.101]\n",
      "      test loss:  0.245 [ 0.377  0.113]\n",
      "    * Epoch: 7\n",
      "      train loss:  0.209 [ 0.347  0.107]\n",
      "      test loss:  0.243 [ 0.361  0.125]\n",
      "    * Epoch: 8\n",
      "      train loss:  0.210 [ 0.386  0.119]\n",
      "      test loss:  0.291 [ 0.421  0.161]\n",
      "    * Epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-23 21:58:54,346] Trial 99 finished with value: 0.3511927127838135 and parameters: {'lr': 0.001220524032668122, 'gamma': 0.9539199670725702, 'batch_size': 173}. Best is trial 94 with value: 0.3421245813369751.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      train loss:  0.205 [ 0.339  0.092]\n",
      "      test loss:  0.228 [ 0.351  0.105]\n",
      "Final result:\n",
      "  train dice loss =  0.338899165391922\n",
      "  test dice loss =  0.3511927127838135\n"
     ]
    }
   ],
   "source": [
    "# Somewhere else is our function train_model(lr, gamma, batch_size);\n",
    "# it should train and return a model.\n",
    "# The return value should be a tuple (model, loss) where loss is the\n",
    "# validation dataset loss for the trained model.\n",
    "\n",
    "# The train_ds needs to be defined before the code below gets run.\n",
    "runno = 1\n",
    "data_path = Path(f'/data/vines-thermal/optuna/run{runno}')\n",
    "model_save_path = data_path / 'models'\n",
    "study_db_path = data_path / 'study.db'\n",
    "study_name = 'vines-thermal'\n",
    "\n",
    "if not data_path.exists():\n",
    "    data_path.mkdir(mode=0o775, exist_ok=True, parents=True)\n",
    "if not model_save_path.exists():\n",
    "    model_save_path.mkdir(mode=0o775, exist_ok=True, parents=True)\n",
    "\n",
    "def objective(trial):\n",
    "    lr = trial.suggest_float('lr', 0.00001, 0.0025)\n",
    "    gamma = trial.suggest_float('gamma', 0.25, 1)\n",
    "    batch_size = trial.suggest_int('batch_size', 5, 1024)\n",
    "    (model, loss) = train_model(lr, gamma, batch_size)\n",
    "    if model_save_path is not None:\n",
    "        filename = f\"optuna_lr-{lr}_gamma-{gamma}_bs-{batch_size}.pt\"\n",
    "        torch.save(\n",
    "            model.state_dict(),\n",
    "            model_save_path / filename)\n",
    "    return loss\n",
    "\n",
    "study_db = f'sqlite:///{study_db_path}'\n",
    "study = optuna.create_study(\n",
    "    study_name=study_name,\n",
    "    storage=study_db,\n",
    "    load_if_exists=True)\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "savedata = dict(study.best_params, best_dice=study.best_value)\n",
    "with (data_path / 'best_params.json').open('w') as file:\n",
    "    json.dump(savedata, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Vines-Thermal Python Kernel",
   "language": "python",
   "name": "vines"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
